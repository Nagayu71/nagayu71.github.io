[
  {
    "objectID": "posts/2024/QuantMacro/numerical_computation.html",
    "href": "posts/2024/QuantMacro/numerical_computation.html",
    "title": "定量的マクロ経済学における数値計算の基礎",
    "section": "",
    "text": "\\[\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\N}{\\mathbb{N}}\n\\newcommand{\\Z}{\\mathbb{Z}}\n\\newcommand{\\G}{\\mathcal{G}}\n\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\n\\newcommand{\\Abs}[1]{\\left|#1\\right|}\n\\newcommand{\\norm}[1]{\\|#1\\|}\n\\newcommand{\\Norm}[1]{\\left\\|#1\\right\\|}\n\\newcommand{\\SquareBrac}[1]{\\left[#1\\right]}\n\\newcommand{\\Brace}[1]{\\left\\{#1\\right\\}}\n\\newcommand{\\Paren}[1]{\\left(#1\\right)}\n\\newcommand{\\brac}[1]{\\langle#1\\rangle}\n\\newcommand{\\Brac}[1]{\\left\\langle#1\\right\\rangle}\n\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\n\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\n\\newcommand{\\ov}[1]{\\overline{#1}}\n\\newcommand{\\un}[1]{\\underline{#1}}\n\\newcommand{\\wt}[1]{\\widetilde{#1}}\n\\newcommand{\\wh}[1]{\\widehat{#1}}\n\\newcommand{\\pp}[2]{\\frac{\\partial #1}{\\partial #2}}\n\\newcommand{\\ppp}[3]{\\frac{\\partial #1}{\\partial #2\\partial #3}}\n\\newcommand{\\dd}[2]{\\frac{d #1}{d #2}}\n\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\n\\newcommand{\\Floor}[1]{\\left\\lfloor#1\\right\\rfloor}\n\\newcommand{\\ceil}[1]{\\lceil#1\\rceil}\n\\newcommand{\\Ceil}[1]{\\left\\lceil#1\\rceil\\right}\n\\newcommand{\\iso}{\\overset{\\sim}{\\to}}\n\\newcommand{\\eqDescribe}[2]{\\underbrace{#1}_{\\text{#2}}}\n\\newcommand{\\bm}[1]{\\boldsymbol{#1}}\n\\newcommand{\\argmax}{\\operatorname*{argmax}}\n\\newcommand{\\argmin}{\\operatorname*{argmin}}\n\\]"
  },
  {
    "objectID": "posts/2024/QuantMacro/numerical_computation.html#はじめに",
    "href": "posts/2024/QuantMacro/numerical_computation.html#はじめに",
    "title": "定量的マクロ経済学における数値計算の基礎",
    "section": "1 はじめに",
    "text": "1 はじめに\n今年の6月に『定量的マクロ経済学と数値計算』という本が出版された (北尾早霧, 砂川武貴, and 山田知明 2024)．\n近年マクロ経済学のモデルが複雑になるにつれて，コンピュータを使って近似的にモデルの性質を理解するアプローチが広まっている．\nしかし，日本のマクロ経済学教育の中で，それを可能にする数値計算 (numerical computation) という分析手法を学ぶ機会は乏しい．\nこの状況を憂いた著者陣が，『経済セミナー』という雑誌に投稿した連載を書籍化したのが本書である．\n本書が扱う内容は，現代的なマクロ経済学のベースラインとなりつつあるトピックであり，教育が手薄になるのは好ましくない．\n\n本書が扱う内容は現在のマクロ経済学のメインストリームの１つといっても過言ではない。＜中略＞本書を通じて現代のマクロ経済分析に必要な新たな道具を身に付けるサポートをすることが、我々の目的である。(p.8)\n\n（気持ちネットワークを扱うモデルをメインにやっているとはいえ，）マクロ経済学徒の一人としては現代的な分析手法を学ぶ必要があると感じたため，勉強ノートを作ろうと思い立った次第である．\n\n\n\n\n\n\nこのウェブサイトのフレームワークとなっている Quarto は，このようなハンズオンで学ぶスタイルの勉強ノート作成に適している． Quarto もまだまだ勉強中の身ゆえ，このブログは Quarto の勉強も兼ねている．"
  },
  {
    "objectID": "posts/2024/QuantMacro/numerical_computation.html#ベンチマークモデルとカリブレーション",
    "href": "posts/2024/QuantMacro/numerical_computation.html#ベンチマークモデルとカリブレーション",
    "title": "定量的マクロ経済学における数値計算の基礎",
    "section": "2 ベンチマーク・モデルとカリブレーション",
    "text": "2 ベンチマーク・モデルとカリブレーション\nまず，シンプルな２期間モデルを用いて数値計算手法の基本的な使い方のイメージをつかむ．\n現在のマクロ経済学でベンチマークとなっている新古典派成長モデルは，この２期間モデルを多期間に拡張していき，その極限をとって無限期間にしたものである．\nしたがって，まずはこのシンプルな２期間モデルで数値計算の基礎をおさえておくことが重要である．\n\n2.1 ベンチマーク・モデル：２期間モデル\nある経済主体の人生全体での消費・貯蓄行動をモデル化しよう．\n経済主体は若年期に働いて所得 \\(w\\) を獲得し，その所得を若年期の消費 \\(c_1\\) に充てるか，それとも老後のための貯蓄 \\(a\\) に残すかを決める問題に直面している．\n若年期の予算制約は，\n\\[\nc_1 + a = w\n\\tag{1}\\]\nであり，老年期の予算制約は若年期の貯蓄に金利 \\(r\\) が付き，また遺産動機はないとすると，\n\\[\nc_2 = a(1 + r)\n\\tag{2}\\]\nで与えられる．\\(\\beta &gt; 0\\) を割引因子 (discount factor) とすると，経済主体の生涯効用は次式で与えられる：\n\\[\nU(c_1, c_2) = u(c_1) + \\beta u(c_2).\n\\tag{3}\\]\n右辺第２項だが，主体は若年期に意思決定を行うため，将来の消費 \\(c_2\\) から得られる効用 \\(u(c_2)\\) は割り引かれる．\nここで，効用関数について \\(u'(c) &gt; 0\\) および \\(u''(c) &lt; 0\\) を仮定し，主体は消費の平準化 (consumption smoothing) を望むものとする1．\n以上の設定の下で解くべき意思決定問題は，次のように定式化できる．\n\\[\n\\begin{aligned}\n\\max_{c_1, c_2, a} & \\quad U(c_1, c_2) = u(c_1) + \\beta u(c_2) \\\\\n\\text{s.t.} & \\quad c_1 + a = w, \\\\\n& \\quad c_2 = (1+r)a. \\\\\n\\end{aligned}\n\\tag{4}\\]\nラグランジアンは\n\\[\n\\mathcal{L} = u(c_1) + \\beta u(c_2) + \\lambda_1 (w - c_1 - a) + \\lambda_2[(1+r)a - c_2]\n\\]\nより，一階条件は\n\\[\n\\begin{aligned}\n&0 = \\frac{\\partial\\mathcal{L}}{\\partial c_1} = u'(c_1) - \\lambda_1,\\\\\n&0 = \\frac{\\partial\\mathcal{L}}{\\partial c_2} = \\beta u'(c_2) - \\lambda_2,\\\\\n&0 = \\frac{\\partial\\mathcal{L}}{\\partial a} = -\\lambda_1 + \\lambda_2(1+r).\n\\end{aligned}\n\\]\n整理すると 式 5 のオイラー条件（オイラー方程式）を得る．\n\\[\nu'(c_1) = \\beta (1+r) u'(c_2).\n\\tag{5}\\]\nオイラー条件（式 5）の直感的な意味は，若年期と老年期で極端に消費水準が変動することを嫌うリスク回避的な主体は，若年期の消費 \\(c_1\\) から得られる限界効用 \\(u'(c_1)\\) と，老年期の消費 \\(c_2\\) から得られる限界効用の割引現在価値 \\(\\beta (1+r) u'(c_2)\\) が一致するように消費計画を決めるということである．\n\n\n\n\n\n\nところで，何をもってモデルを「解いた」と言えるのか．マクロモデルはさまざまな経済変数が登場するため，この点を整理しておかないとすぐに迷子になる．\nこのモデルの内生変数は \\(c_1\\) と \\(a\\) であり，外生変数は \\(w\\) であるから2，モデルを解くにはある所得 \\(w\\) のもとでの主体の貯蓄関数 \\(g(w)\\) と消費関数 \\(h(w)\\) を導出すれば良い：\n\\[\n\\begin{aligned}\na &= g(w), \\\\\nc_1 &= h(w).\n\\end{aligned}\n\\]\nこの例のように，\n\\[\n\\text{内生変数} = f(\\text{外生変数})\n\\]\nと内生変数が外生変数の関数として書けるとき，「モデルが解けた」という．\n\n\n\n\n\n2.2 カリブレーション\n２期間モデルは人間にとってはシンプルなモデルだが，コンピュータにとってはそうではない．\nというのも，効用関数 \\(u(c)\\) という表現は抽象的で，コンピュータには理解できないからである．\nそこで，コンピュータが理解できる形で効用関数を「特定化」する必要がある．\nここでは，マクロ経済学で頻繁に使われる相対的リスク回避度一定 (constant relative risk aversion: CRRA) 型効用関数を仮定する．\n\\[\nu(c) = \\frac{c^{1-\\gamma}}{1-\\gamma}.\n\\tag{6}\\]\nリスクが存在するモデルであれば，\\(\\gamma\\) は相対的リスク回避度 (coefficient of relative risk aversion) であり，同時に異時点間の代替の弾力性 (intertemporal elasticity of substitution) の逆数である．\n式 6 をコンピュータが認識できるように Python で書くと，次のようになる．\n\nimport numpy as np\n\ndef CRRA(c, gamma):\n    if gamma != 1.0:\n        util = c**(1.0 - gamma) / (1.0 - gamma)\n    else:\n1        util = np.log(c)\n    return util\n\n\n1\n\n\\(\\gamma = 1\\) の場合に \\(u(c) = \\log c\\) としているのは 式 6 が \\(c \\to 1\\) の極限で発散するため，次式のようにロピタルの定理で解消した結果である．\\[\n\\begin{aligned}\n\\lim_{\\gamma\\to1} u(c)\n&= \\lim_{\\gamma\\to1} \\frac{c^{1-\\gamma}}{1-\\gamma} \\\\\n&= \\lim_{\\gamma\\to1} \\frac{-c^{1-\\gamma} \\log c}{-1} \\\\\n&= \\lim_{\\gamma\\to1} c^{1-\\gamma}\\log c \\\\\n&= \\log c\n\\end{aligned}\\]\n\n\n\n\n実際にプログラムを動かす際は，関数形の特定に加えて具体的にパラメータの値を決める必要があるが，このように関数形を特定してパラメータを定める一連の作業をカリブレーション (calibration) と呼ぶ．\n異なる gamma の下で CRRA 型効用関数（式 6）を可視化したものが 図 1 である．\n\n\nShow the code\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n# c の範囲を指定して曲線をプロット\n1c = np.linspace(start=0.1, stop=1.0, num=100)\n\ngammas = [1, 1.5, 2]\nfor gamma in gammas:\n    u = CRRA(c, gamma)\n    ax.plot(c, u, label=f'gamma = {gamma}')\nax.set_title(\"Utility Function for Different gamma values\")\nax.set_xlabel(r\"$c$\")\nax.set_ylabel(r\"$u(c)$\")\nax.legend()\nax.grid()\npass\n\n\n\n1\n\n0.1 から 10 までの値 (0 は定義できないので 0.1 から)\n\n\n\n\n\n\n\n\n\n\n図 1: CRRA 型効用関数\n\n\n\n\n\nベンチマーク・モデルでは人生を 2 期間に分けているので，モデル上の 1 期間を 30 年と想定する． そのため，割引因子 \\(\\beta\\) と金利 \\(r\\) は年率ではなく 30 年間の値を使う．\n今回は実際に 1 期間を 30 年でカリブレートしている Song, Storesletten, and Zilibotti (2012) の値を拝借する．割引因子は年率で \\(\\beta = 0.985\\) として，1 期間は 30 年なので 30 乗する（\\(\\beta = 0.985^{30}\\)）．金利は年率で \\(2.5\\%\\) と設定すると \\(1+r = 1.025^{30}\\) となる．相対的リスク回避度は，よく使われる値の \\(\\gamma = 2\\) としておく．\n\nbeta = 0.985**30        # 割引因子\ngamma = 2.0             # 相対的危険回避度\nr = 1.025**30 - 1.0     # 金利\n\n\n\n2.3 解析解の性質\n数値計算に入る前に，２期間モデルの解析解の性質を簡単に確認しておく．今回のモデルはシンプルなので，貯蓄関数 \\(a = g(w)\\) を手計算で求めることができる．\n\\[\n% \\begin{equation}\na = \\frac{w}{1+(1+r)\\{\\beta(1+r)\\}^{-1/\\gamma}}\n% \\end{equation}\n\\tag{7}\\]\n\n\n\n\n\n\n導出\n\n\n\n\n\nオイラー条件（式 5）に予算制約の 式 1 と 式 2 を代入すると，\n\\[\n\\begin{aligned}\n(w-a)^{-\\gamma} &= \\beta(1+r)\\SquareBrac{(1+r)a}^{-\\gamma} \\\\\n(w-a) &= \\SquareBrac{\\beta(1+r)}^{-1/\\gamma}(1+r)a \\\\\nw &= \\Brace{1+\\SquareBrac{\\beta(1+r)}^{-1/\\gamma}(1+r)}a.\n\\end{aligned}\n\\]\n\n\n\nこれがモデルから導出される真の貯蓄関数であり，内生変数 \\(a\\) が外生変数 \\(w, r, \\beta, \\gamma\\) で表されているので，これでモデルは解けている．\n貯蓄関数（式 7）は若年期の所得 \\(w\\) の連続な線形の増加関数になっており，そのグラフを可視化したものが 図 2 である．\n\n\nShow the code\n1import japanize_matplotlib\n\n# 傾き\nslope = 1 / (1 + (1+r) * (beta*(1+r)) **(-1/gamma))\n\n# 貯蓄関数\ndef saving(w, beta, r, gamma):\n    return w / (1 + (1+r) * (beta*(1+r)) **(-1/gamma))\n\nfig, ax = plt.subplots()\n\nw = np.linspace(start=0, stop=1.0, num=100)\na = saving(w, beta, r, gamma)\nax.plot(w, a, c=\"#FF7A72\")\nax.set(title=\"貯蓄関数\", xlabel=\"若年期の所得: \"+r\"$w$\", ylabel=\"若年期の貯蓄: \"+r\"$a=g(w)$\", xlim=(0,1), ylim=(0,0.4))\nax.grid()\npass\n\n\n\n1\n\nタイトルや軸ラベルを日本語で書くときに必要\n\n\n\n\n\n\n\n\n\n\n図 2: 解析的に求めた貯蓄関数"
  },
  {
    "objectID": "posts/2024/QuantMacro/numerical_computation.html#実践数値計算",
    "href": "posts/2024/QuantMacro/numerical_computation.html#実践数値計算",
    "title": "定量的マクロ経済学における数値計算の基礎",
    "section": "3 【実践】数値計算",
    "text": "3 【実践】数値計算\n\n3.1 離散近似とグリッド\n貯蓄関数（式 7）は連続関数であるが，コンピュータは連続という概念をそのままの形では理解できない．\nそこで，数値計算においては基本的に，連続な変数を有限の \\(N\\) 個の点に離散化 (discretize) して考える必要がある．\n\n3.1.1 グリッド上で計算する\n若年期の所得 \\(w\\) がとりうる値は，\\(w_i \\in \\{w_1,\\ldots,w_N\\}\\) の範囲にあるとする．\n\n\n\n\n\n\nコンピュータは無限を扱えないので，\\(w \\in [0, \\infty)\\) や \\(w \\in (-\\infty, \\infty)\\) のような範囲を扱うことはできない． 数値計算において，定義域は必ず有界 (finite)である必要がある．\n\n\n\n所得を \\(N\\) 個に離散化するということは，若年期の所得に応じて \\(N\\) 種類の経済主体が存在している状況を作り出すということである．\nこの離散的な点の集まりをグリッド (grid) あるいはノード (node) と呼ぶ． また，それぞれの点はグリッドポイント (grid point) あるいは評価点 (evaluation point) と呼ばれている．\nここでは単純に，若年期の所得 \\(w\\) は \\([0.1, 1]\\) 区間の間に \\(0.1\\) 刻みで \\(10\\) 個の点\n\\[\nw_i \\in \\{0.1, 0.2,\\ldots, 1.0\\}\n\\]\nとして存在していると考える．\n\nnw = 10       # 所得グリッドの数\nw_min = 0.1   # 所得の最大値\nw_max = 1.0   # 所得の最小値\ngrid_w = np.linspace(start=0.1, stop=1.0, num=10)\nprint(grid_w)\n\n[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n\n\n\n\n\n\n\n\nこの意思決定問題では \\(w_i = 0\\) を含めると若年期も老年期も消費ができなくなってしまうため，最小値は正値にしておく必要がある．\n\n\n\n\n\n\n3.2 状態変数と制御変数がともに離散の場合：グリッドサーチ\n\n\n\n\n\n\n用語の導入\n\n\n\n最適化問題を解く際にすでに決まっている若年期の所得 \\(w\\) を状態変数 (state variable) と呼び，意思決定において選択する若年期の貯蓄 \\(a\\) を制御変数 (control variable) と呼ぶ． また，貯蓄関数のような意思決定関数は政策関数 (policy function) と呼ばれる．\n\n\nまずは，所得 \\(w\\) と資産 \\(a\\) がともに離散的な場合に２期間モデルを解く方法を見る．\nすなわち，状態変数 \\(w\\) だけでなく，制御変数 \\(a\\) についても離散化を行う．\nここでは\n\\[\na_j \\in \\{0.025, 0.05, 0.075, 0.1, \\ldots, 1.0\\}\n\\]\nと \\(0.025\\) 刻みで \\(40\\) 個のグリッドをとる3．\n\nna = 40       # 貯蓄グリッドの数\na_min = 0.025 # 貯蓄の最小値\na_max = 1.0   # 貯蓄の最大値\ngrid_a = np.linspace(start=a_min, stop=a_max, num=na)\nprint(grid_a)\n\n[0.025 0.05  0.075 0.1   0.125 0.15  0.175 0.2   0.225 0.25  0.275 0.3\n 0.325 0.35  0.375 0.4   0.425 0.45  0.475 0.5   0.525 0.55  0.575 0.6\n 0.625 0.65  0.675 0.7   0.725 0.75  0.775 0.8   0.825 0.85  0.875 0.9\n 0.925 0.95  0.975 1.   ]\n\n\nこのような離散化を行うと，解くべき効用最大化問題（式 4）は，所与の \\(w_i\\) について，\n\\[\n\\max_{a_j} \\quad\n\\frac{[w_i-a_j]^{1-\\gamma}}{1-\\gamma} + \\beta\\frac{[(1+r)a_j]^{1-\\gamma}}{1-\\gamma}\n\\tag{8}\\]\nと書き直すことができる．\n組み合わせの数は，所得 \\(w_i\\) と資産 \\(a_j\\) がそれぞれ \\(10\\) 通りと \\(40\\) 通りあるので， \\(400\\) 通りとなる．\nそして各所得 \\(w_i\\) のもとで \\(40\\) 種類の資産 \\(a_j\\) の中から生涯効用（式 8）を最大化する資産 \\(a^*\\) を求めれば良いので，これくらいであれば「総当たり」で求めることができる．\n\n1obj = np.zeros((na, nw))\n\n# 状態変数と制御変数のすべての組み合わせ (w,a) について生涯効用を計算\nfor i in range(nw):\n    for j in range(na):\n        c = grid_w[i] - grid_a[j]\n        if c &gt; 0:\n            obj[j, i] = CRRA(c, gamma) + beta * CRRA((1+r)*grid_a[j], gamma)\n2        else:\n            obj[j, i] = -10000.0 \n\n\n1\n\n各 \\((w_i, a_j)\\) での生涯効用を格納するna \\(\\times\\) nw ゼロ行列\n\n2\n\n消費が負になる場合，負の効用を与えて最適化でこの値が選ばれないようにしておく\n\n\n\n\n試しに，w = 0.5, 0.8, 1.0 のときの生涯効用を可視化してみよう（図 3）．\n\n\nShow the code\nfig, ax = plt.subplots()\nax.plot(grid_a, obj[:,4], c=\"b\", label=\"w=0.5\")\nax.plot(grid_a, obj[:,7], c=\"r\", label=\"w=0.8\")\nax.plot(grid_a, obj[:,9], c=\"g\", label=\"w=1.0\")\nax.set(xlabel=\"若年期の貯蓄(老年期の資産): \"+r\"$a$\", ylabel=\"生涯効用: \"+r\"$U(c_1,c_2)$\", xlim=(0,1), ylim=(-10,0))\nax.legend()\nax.grid(ls=\"--\")\npass\n\n\n\n\n\n\n\n\n図 3: 生涯効用\n\n\n\n\n\n図 3 では若年期の所得 \\(w_i\\) の下での生涯効用 \\(U(a_j; w_i)\\) が凹関数として可視化されている．\n直感的にそれぞれの山の頂上に対応する貯蓄点が，求めたい最適貯蓄だとわかるだろう．\nそこで，若年期の所得 \\(w_i\\) ごとに最適な貯蓄点 \\(a_j\\) を計算し，求めた貯蓄関数を可視化する（図 4）．\n\n1pol = np.zeros(nw)\nfor i in range(nw):\n2    maximizer = np.argmax(obj[:, i])\n    pol[i] = grid_a[maximizer]\n\nfig, ax = plt.subplots()\nax.plot(grid_w, saving(grid_w, beta, r, gamma), c=\"#FF7A72\",label=\"解析解\")\nax.plot(grid_w, pol, c=\"#78C2AD\", marker=\"o\", label=\"グリッドサーチ\")\nax.set(title=\"貯蓄関数\", xlabel=\"若年期の所得: \"+r\"$w$\", ylabel=\"若年期の貯蓄: \"+r\"$a=g(w)$\")\nax.grid(ls=\"--\")\nax.legend()\npass\n\n\n1\n\n政策関数（貯蓄関数）を格納するゼロベクトル\n\n2\n\n生涯効用が最大値をとる点を探し，そのインデックスを取得する\n\n\n\n\n\n\n\n\n\n\n図 4: グリッドサーチで求めた貯蓄関数\n\n\n\n\n\n図 4 を見ると，グリッドサーチで求めた最適貯蓄（緑色の点）が，解析解（赤色の直線）からあまり離れていないことがわかる．\n\n\n\n\n\n\nグリッドサーチのグラフは点同士を直線でつないだ折れ線グラフのように見えるが，これは plot() 関数の仕様によるものである．実際には，状態変数 \\(w\\) のグリッドポイント上でしか最適貯蓄 \\(a\\) を求めていないことに注意されたい．\n\n\n\nグリッドサーチで精度を上げるには，離散化するグリッドの数を増やせば良さそうだが，考えているモデルによっては次のセクションで扱う「次元の呪い」という問題にぶつかる．\n\n3.2.1 注意点：次元の呪い\n状態変数と制御変数をどちらも離散化して，とりうる全ての組み合わせを計算するというグリッドサーチのアプローチは，単純ではあるが複雑な非線形モデルにも使えるのでなかなか侮れない．\nたとえば，政策関数の形状や性質がよくわかっていないモデルを解く場合，とりあえずグリッドを切ってモデルの性質を大雑把に掴むというアプローチは有効である．\nしかし，このアプローチは次元の呪い (curse of dimensionality) の影響をダイレクトに受けるので，計算に時間がかかる傾向にある．\n状態変数の数が \\(n\\) 個のとき，最適貯蓄を計算する必要のあるグリッドポイントの数は\n\\[\n(\\text{状態変数のグリッド数})^n\n\\]\nで与えられる．したがって，たとえば教育水準の違いや性別の違いを考慮できるように若年期における状態変数を増やしていくと，計算時間は指数的に増えてしまう．\n\n\n\n\n\n\n次元の呪い\n\n\n\n状態変数を増やせば増やすほど，計算時間は指数的に増える．そのため，現実的な計算時間で複雑なモデルを高い精度で解くための工夫が常に求められる．\n\n\n\n\n3.2.2 オブジェクト指向プログラミング\n数値計算では，コンピュータが理解できるように関数を特定化してパラメータを設定するカリブレーションという作業が必要なのであった．\nここまでの実装では，逐一関数を定義してパラメータを指定していた．\nしかし，その方法ではパラメータが変わった時にモデルの振る舞いがどう変わるかを分析する比較静学のような場面で苦労しそうなのは容易に想像できる．\nそこで，オブジェクト指向プログラミングのクラス (class) という機能でモデルのテンプレートを作っておくと便利である．\n```{python}\nclass Models:\n    def __init__(self, beta, gamma, r, nw, w_min, w_max, grid_w, na, a_min, a_max, grid_a):\n        self.beta = beta\n        self.gamma = gamma\n        self.r = r\n        self.nw = nw\n        self.w_min = w_min\n        self.w_max = w_max\n        self.grid_w = grid_w\n        self.na = na\n        self.a_min = a_min\n        self.a_max = a_max\n        self.grid_a = grid_a\n```\nカリブレーションを行う際は Models を定義した上で，次の Calibration() 関数を実行する．\n```{python}\ndef Calibration():\n    beta = 0.985 ** 30\n    gamma = 2.0\n    r = 1.025**30 - 1.0\n    nw = 10\n    w_min = 0.1\n    w_max = 1.0\n    na = 40\n    a_min = 0.025\n    a_max = 1.0\n\n    grid_w = np.linspace(w_min, w_max, nw)\n    grid_a = np.linspace(a_min, a_max, na)\n    return Models(beta, gamma, r, nw, w_min, w_max, grid_w, na, a_min, a_max, grid_a)\n```\nこのノートでもこれ以降は，クラスを使ってさまざまなパラメータを管理する．\n\n\n\n3.3 最適化アルゴリズム\nグリッドサーチはモデルを拡張した場合に計算量が指数的に増加するのに加え，グリッド数を節約すると精度が悪化するという問題を抱えていた．\n実際，真の貯蓄関数は 図 2 のように線形である一方，グリッドサーチで求めた貯蓄関数は 図 4 にあるように直線ではない．\nそこで，状態変数 \\(w\\) は § 3.2 と同様に離散化するが，連続な制御変数 \\(a\\) を許容するより洗練されたアプローチを採用しよう．\nグリッドサーチで考えた問題（式 8）で離散化していた \\(a_j\\) を連続値にするので，今考えている最適化問題は次式で表される．\n\\[\n\\max_{a\\in\\R} \\quad\n\\frac{[w_i-a]^{1-\\gamma}}{1-\\gamma} + \\beta\\frac{[(1+r)a]^{1-\\gamma}}{1-\\gamma}\n\\tag{9}\\]\n式 9 のような最適化問題を数値計算で解くには，数値計算ソフトに標準的に実装されている最適化ライブラリを用いれば良い．\n大抵は，目的関数とその関数のパラメータを入力として受け取り，目的関数の最大値や最小値を探索する仕様になっている．\n最適化問題（式 9）であれば，カリブレーションしたパラメータ \\(\\{\\beta, \\gamma, r\\}\\) を所与として，各状態変数 \\(w_i \\in \\Brace{w_1, \\ldots, w_N}\\) の下で生涯効用の最大値とそれを与える最大元 \\(a\\) を探索してくれる．\n\n3.3.1 実装\nまず，カリブレーションを § 3.2.2 で導入した方法で行う．\n\nclass Models:\n    def __init__(self, beta, gamma, r, nw, w_min, w_max, grid_w):\n        self.beta = beta\n        self.gamma = gamma\n        self.r = r\n        self.nw = nw\n        self.w_min = w_min\n        self.w_max = w_max\n        self.grid_w = grid_w\n\ndef Calibration():\n    beta = 0.985 ** 30\n    gamma = 2.0\n    r = 1.025**30 - 1.0\n    nw = 10\n    w_min = 0.1\n    w_max = 1.0\n\n    grid_w = np.linspace(w_min, w_max, nw)\n    return Models(beta, gamma, r, nw, w_min, w_max, grid_w)\n\nCalibration() 関数を実行することで，Calibration() 内で定義されたパラメータを情報として持つ Models インスタンスが生成されるので，params に代入しておく．\n\nparams = Calibration()\n\nここでは，scipy の optimize モジュールにある fminbound() 関数を使って最適化問題（式 9）を解く4．\n\nfrom scipy import optimize\n\nでは，optimize.fminbound() に渡す目的関数を定義しよう．最小化問題に変換するために \\(-1\\) をかけている．\n\\[\n\\text{obj}(a, w_i;\\beta, \\gamma, r) = -\\Brace{\\frac{[w_i-a]^{1-\\gamma}}{1-\\gamma} + \\beta\\frac{[(1+r)a]^{1-\\gamma}}{1-\\gamma}}\n\\]\n\ndef obj(a, w_i, params):\n    c = w_i - a\n    if c &gt; 0:\n        life_util = CRRA(c, params.gamma) + params.beta * CRRA((1+params.r)*a, params.gamma)\n    else:\n        life_util = -100000.0\n    return -1.0 * life_util\n\n\n\n\n\n\n\n上の obj() は a, w_i, params の３つの引数を持つが，実際に optimize.fminbound() に渡すときは，最適化を行う a だけの関数にしておく必要がある．\n\n\n\n所与の状態変数 \\(w_i\\) に対して制御変数 \\(a\\) についての最適化問題を解けば良いので，grid_w についての for ループ内で optimize.fminbound() を使えば良い．\n\n1opt_a = np.zeros(params.nw)\n\nfor i, w_i in enumerate(params.grid_w):\n2    obj_specified = lambda a: obj(a, w_i, params)\n    opt_a[i] = optimize.fminbound(obj_specified, w_i*0.01, w_i*2.0)\nprint(f\"最適貯蓄の配列: \\n{opt_a}\")\n\n\n1\n\n各 \\(w_i\\) の下での最適貯蓄を格納する配列\n\n2\n\noptimize.fminbound() に渡すために，obj() を a だけの関数にする\n\n\n\n\n最適貯蓄の配列: \n[0.03550017 0.07100034 0.10650385 0.14200403 0.17750421 0.21300505\n 0.24850589 0.28400673 0.31950757 0.35500841]\n\n\nopt_a には grid_w の各 \\(w_i\\) に対する最適貯蓄 \\(a\\) が格納してある．これを可視化したものが 図 5 である．\n\nfig, ax = plt.subplots()\nax.grid(ls=\"--\")\nax.scatter(params.grid_w, saving(params.grid_w, params.beta, params.r, params.gamma), c=\"#FF7A72\",label=\"解析解\")\nax.plot(params.grid_w, opt_a, c=\"#78C2AD\",label=\"アルゴリズム\")\nax.set(title=\"貯蓄関数\", xlabel=\"若年期の所得: \"+r\"$w$\", ylabel=\"若年期の貯蓄: \"+r\"$a=g(w)$\")\nax.legend()\npass\n\n\n\n\n\n\n\n図 5: 最適化アルゴリズムから導出した貯蓄関数\n\n\n\n\n\n同じグリッドポイントを使っているが，グリッドサーチで求めた 図 4 と違って，最適化アルゴリズムで導出した 図 5 は解析的な解（図 2）が示す綺麗な直線になっており，計算精度が大幅に改善された様子がわかる5．\nこれは制御変数 \\(a\\) がとりうる値を連続値にしたことに起因する．\n\n\n\n3.4 １階条件を使う\nモデルの解が満たすべきオイラー条件（式 5）をうまく使って数値計算を行うアプローチもある．\nここでは，オイラー条件を求根問題に落とし込んで解く方法（§ 3.4.1）と，政策関数自体をパラメトリックに近似する方法（§ 3.4.2）を扱う．\n\n3.4.1 非線形方程式の求根問題\nオイラー条件（式 5）に予算制約を代入すると次式を得る．\n\\[\nu'(w-a) = \\beta(1+r)u'((1+r)a)\n\\tag{10}\\]\n状態変数 \\(w\\) を \\(w_i\\) と離散化して，それぞれの変数の役割を見てみると\n\\[\nu'(\\eqDescribe{w_i}{given} - \\eqDescribe{a}{control}) =\n\\eqDescribe{\\beta(1+r)}{parameter}u'(\\eqDescribe{(1+r)}{parameter}\\ \\eqDescribe{a}{control})\n\\]\nなので，未知変数は \\(a\\) だけである．そこで，式 10 を変形して次式で残差関数 (residual function) を定義する：\n\\[\nR(a;w_i) \\equiv\n\\beta(1+r)\\frac{u'((1+r)a)}{u'(w_i-a)} - 1.\n\\tag{11}\\]\n式 11 を使うと，オイラー条件を満たす制御変数 \\(a\\) を見つける問題を，\n\\[\nR(a;w_i) = 0\n\\]\nとなる \\(a\\) を探すという求根（ゼロ点）問題 (root-finding problem) に変換することができる．\n一般に，オイラー条件を変換して得た残差関数（式 11）は，複雑な形をした非線形方程式である可能性があるが，非線形方程式のゼロ点を探すアルゴリズムの研究は長い歴史を持つため，様々なアプローチが考案されている．\n\n3.4.1.1 実装\n求根問題は scipy.optimize.fsolve() 関数で解くことができる． ここではカリブレーションは § 3.3 のものを再び使用する．\nまずはソルバーに渡す残差関数（式 11）を実装しよう．残差関数内にある限界効用 (marginal utility) は\n\\[\nu'(c) = c^{-\\gamma}\n\\]\nで与えられるので，Python で表すと次のようになる．\n\ndef marginal_util(c, gamma):\n    return c ** (- gamma)\n\nこれを用いると残差関数は次のように実装できる．\n\n\n\n\nCode 1: 残差関数\n\n\ndef resid(a, w_i, params):\n    c = w_i - a\n    if c &gt; 0:\n        mu_y = marginal_util(c, params.gamma)              # 若年期の限界効用\n    else:\n        mu_y = 10000.0\n    mu_o = marginal_util((1+params.r)*a, params.gamma)     # 老年期の限界効用\n    return params.beta * (1+params.r) * (mu_o/mu_y) - 1.0\n\n\n\n\n§ 3.3 と同様に，ソルバーを使って各状態変数 \\(w_i\\) の下で最適貯蓄を求めていく．\n\n1opt_a = np.zeros(params.nw)\n\nfor i, w_i in enumerate(params.grid_w):\n2    resid_specified = lambda a: resid(a, w_i, params)\n3    opt_a[i] = optimize.fsolve(resid_specified, x0=0.01)[0]\nprint(f\"最適貯蓄の配列: \\n{opt_a}\")\n\n\n1\n\n各 \\(w_i\\) の下での最適貯蓄を格納する配列\n\n2\n\noptimize.fsolve() に渡すために，resid() を a だけの関数にする\n\n3\n\n我々が欲しい最適な \\(a\\) は optimize.fsolve() の返り値の最初の要素に格納されている\n\n\n\n\n最適貯蓄の配列: \n[0.03550089 0.07100178 0.10650266 0.14200355 0.17750444 0.21300533\n 0.24850621 0.2840071  0.31950799 0.35500888]\n\n\n結果を図示した 図 6 を見ると，アルゴリズムで求めた解が解析解の直線上に乗っている様子がわかる．\n\nfig, ax = plt.subplots()\nax.grid(ls=\"--\")\nax.plot(params.grid_w, saving(params.grid_w, params.beta, params.r, params.gamma), c=\"#FF7A72\",label=\"解析解\")\nax.scatter(params.grid_w, opt_a, c=\"#78C2AD\", label=\"アルゴリズム\")\nax.set(title=\"貯蓄関数\", xlabel=\"若年期の所得: \"+r\"$w$\", ylabel=\"若年期の貯蓄: \"+r\"$a=g(w)$\")\nax.legend()\npass\n\n\n\n\n\n\n\n図 6: 求根アルゴリズムから導出した貯蓄関数\n\n\n\n\n\n\n\n\n3.4.2 パラメトリックな近似：射影法\n最適化（§ 3.3）と求根アルゴリズム（§ 3.4.1）を使った手法はどちらも，本来連続値をとる現在の所得水準 \\(w\\) を有限個に離散化して，そのグリッドポイント上で最適貯蓄を計算するという点は共通している．\nこれに対して，射影法 (projection method) では求めたい政策関数そのものをパラメトリックに近似するというアプローチをとる6．\n今考えている政策関数は若年期の所得 \\(w\\) を変数にとる貯蓄関数 \\(a=g(w)\\) である．貯蓄関数をパラメトリックに近似するとは、貯蓄関数を基底関数 (basis function)  \\(\\{\\Psi_m\\}_{m=0}^M\\) の線形結合 \\(\\hat{g}(w;\\bm{\\theta})\\) で近似するということである7．\n\\[\na = g(w) \\approx \\hat{g}(w;\\bm{\\theta}) = \\sum_{m=0}^M \\theta_m\\Psi_m(w)\n\\tag{12}\\]\nここで \\(\\bm{\\theta} \\equiv \\Paren{\\theta_m}_{m=0}^M\\) は未知の \\(M+1\\) 次元係数ベクトルであり，推定する対象である．\nこの段階では，未知の貯蓄関数 \\(g(w)\\) はきっとパラメトリックな関数 \\(\\hat{g}(w;\\bm{\\theta})\\) で表されるだろうと思っているに過ぎず，何も解決していない．\nしかし，真の貯蓄関数 \\(g(w)\\) はオイラー条件（式 10）を満たすので，それを近似した関数 \\(\\hat{g}(w;\\bm{\\theta})\\) もできるだけオイラー条件を満たしておいて欲しいと思うのは自然な要請である．\nつまり射影法とは，オイラー条件を満たす政策関数を探す問題を，近似関数 \\(\\hat{g}(w;\\bm{\\theta})\\) ができるだけオイラー条件を満たすように係数ベクトル \\(\\bm{\\theta}\\) を決める問題に置き換える手法である．\n以下では基底関数を \\(\\Psi_m(w) = w^m\\) と指定し，貯蓄関数を次の多項式 (polynomial) で近似して議論を進める．\n\\[\na \\approx \\hat{g}(w;\\bm{\\theta}) = \\sum_{m=0}^M \\theta_m w^m\n\\tag{13}\\]\nところで，上述の「できるだけオイラー条件を満たす」ことをどうやって評価すれば良いだろうか．ここで，§ 3.4.1 で定義した残差関数（式 11）を思い出そう．\n仮に近似関数 \\(\\hat{g}(w;\\bm{\\theta})\\) が真の貯蓄関数 \\(g(w)\\) と完全に一致する場合は残差はゼロになり，うまく近似しているのであれば残差はゼロに近いはずである．つまり，\n\\[\nR(\\bm{\\theta}; w) \\equiv\n\\beta (1+r)\\frac{u'((1+r)\\hat{g}(w;\\bm{\\theta}))}{u'(w-\\hat{g}(w;\\bm{\\theta}))} - 1 \\approx 0\n\\tag{14}\\]\nが「あらゆる \\(w\\) で」成り立つ．\n「」をつけたのは，実際に数値計算を行う際コンピュータは連続的な \\(w\\) を扱えないため，任意にとった評価点 \\(\\{w_i\\}_{i=1}^N\\) 上での残差がゼロに限りなく近くなるようなベクトル \\(\\bm{\\theta}\\) を見つける必要があるからである．\n要素に評価点 \\(w_i\\) 上での残差 \\(R(\\bm{\\theta}; w_i)\\) を持つベクトルを \\(\\bm{R}(\\bm{w}; \\bm{\\theta}) \\equiv \\Paren{R(\\bm{\\theta}; w_i)}_{i=1}^N\\) とする． ただし，\\(\\bm{w} = \\Paren{w_i}_{i=1}^N\\) である．\n\\(\\rho(\\cdot, \\cdot)\\) を距離関数 (metric function) とすると，考えている問題は\n\\[\n\\bm{\\theta}^* = \\argmin_\\bm{\\theta} \\rho(\\bm{R}(\\bm{w}; \\bm{\\theta}), \\bm{0})\n\\tag{15}\\]\nと定式化できる．このように，評価点上でのみ距離を測る方法を選点法 (collocation method) と呼ぶ．\n\n3.4.2.1 実装\nカリブレーションは § 3.3 のものを再び使用する．\nここでは多項式 式 13 の次数を \\(M=1\\) として，１次関数 \\(\\hat{g}(w;\\bm{\\theta}) = \\theta_0 + \\theta_1 w\\) で政策関数を近似しよう．\n各評価点 \\(w_i\\) での近似値 \\(\\hat{g}(w_i; \\bm{\\theta})\\) を要素にもつ列ベクトルを \\(\\widehat{\\bm{g}}\\) とすると\n\\[\n\\widehat{\\bm{g}} = \\Paren{\\hat{g}(w_i;\\bm{\\theta})}_{i=1}^N =\n\\begin{pmatrix} \\theta_0 + \\theta_1 w_1 \\\\ \\vdots \\\\ \\theta_0 + \\theta_1 w_i \\\\ \\vdots \\\\ \\theta_0 + \\theta_1 w_N \\end{pmatrix} =\n\\eqDescribe{\\begin{pmatrix} 1 & w_1 \\\\ \\vdots & \\vdots \\\\ 1 & w_i \\\\ \\vdots & \\vdots \\\\ 1 & w_N \\end{pmatrix}}{denoted by X below}\n\\begin{pmatrix} \\theta_0 \\\\ \\theta_1 \\end{pmatrix}\n\\]\nと書けるが，これを実装すると次のようになる．\n\ndef approx_g(theta: np.ndarray, w: np.ndarray) -&gt; np.ndarray:\n    dim = len(theta)\n    nw = len(w)\n1    X = np.zeros((nw, dim))\n    for j in range(dim):\n2        X[:, j] = w ** j\n    return X @ theta\n\n\n1\n\n行列 \\(X\\) を初期化\n\n2\n\n行列 \\(X\\) を作成\n\n\n\n\n次に，残差関数 resid()（Code 1）を利用して，式 14 に従って残差ベクトル \\(\\bm{R}(\\bm{w}; \\bm{\\theta})\\) を実装する．\n\ndef resid_vec(theta, params):\n1    g_hats = approx_g(theta, params.grid_w)\n\n    R = np.zeros(nw)\n    for g, w_i, i in zip(g_hats, params.grid_w, np.arange(nw)):\n        R[i] = resid(g, w_i, params)\n    return R\n\n\n1\n\n貯蓄の近似値ベクトル \\(\\bm{\\hat{g}}\\) を計算\n\n\n\n\nここで，距離関数 \\(\\rho\\) にユークリッド距離を採用すると，考えている問題（式 15）は残差二乗和を最小にする \\(\\bm{\\theta}\\) を見つける非線形最小二乗法に帰着する．\n非線形最小二乗法は scipy.optimize.least_squares() で実装することができる．fun 引数に残差ベクトルを計算する関数を渡せば良い．\n\ndef projection(params, initial_guess=[0.1, 0.35]):\n\n1    resid_specified = lambda theta: resid_vec(theta, params)\n\n    result = optimize.least_squares(fun=resid_specified, x0=initial_guess, method=\"lm\")\n\n2    estimate_g = approx_g(result.x, params.grid_w)\n    return result.x, result.success, estimate_g\n\n\n1\n\noptimize.least_squares() に渡すために，resid_vec() を theta だけの関数にする\n\n2\n\n推定された \\(\\widehat{\\bm{\\theta}}\\) の下での近似関数 \\(\\hat{g}(w; \\widehat{\\bm{\\theta}})\\) を求める\n\n\n\n\nでは，実装した projection() 関数を使って射影法を実際に行おう．\n\nresult = projection(params)\nprint(f\"convergence: {result[1]}\")\nprint(f\"The estimated parameter: {result[0]}\")\n\nconvergence: True\nThe estimated parameter: [-1.90171907e-10  3.55008878e-01]\n\n\n解析解（式 7）によれば，切片はゼロで，傾きは \\(1/1+(1+r)\\{\\beta(1+r)\\}^{-1/\\gamma}\\) から計算すると 0.355 であるから，非常に精度良く近似することができている．\n推定されたパラメータ \\(\\widehat{\\bm{\\theta}}\\) の下での近似関数のグリッド \\(\\widehat{\\bm{g}}(\\bm{w}; \\widehat{\\bm{\\theta}})\\) と真の貯蓄関数を可視化したものが 図 7 である．\n\nfig, ax = plt.subplots()\nax.grid(ls=\"--\")\nax.plot(params.grid_w, saving(params.grid_w, params.beta, params.r, params.gamma), c=\"#FF7A72\",label=\"解析解\")\nax.scatter(params.grid_w, result[2], c=\"#78C2AD\", label=\"射影法\")\nax.set(title=\"貯蓄関数\", xlabel=\"若年期の所得: \"+r\"$w$\", ylabel=\"若年期の貯蓄: \"+r\"$a=g(w)$\")\nax.legend()\npass\n\n\n\n\n\n\n\n図 7: 射影法でパラメトリックに近似した貯蓄関数"
  },
  {
    "objectID": "posts/2024/QuantMacro/numerical_computation.html#footnotes",
    "href": "posts/2024/QuantMacro/numerical_computation.html#footnotes",
    "title": "定量的マクロ経済学における数値計算の基礎",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n効用関数が凹関数であるとき，経済主体はリスク回避的である．↩︎\n経済学では，方程式の解として決まる変数を内生変数 (endogenous variable)，方程式を解く前に値がすでに決まっている変数を外生変数 (exogenous variable) と呼ぶ(神谷和也 and 浦井憲 1996)．外生変数は単にパラメータとか状態変数とも言われる．↩︎\n\\(w_i\\) と同じ離散化をすると，\\(w = 0.1\\) のときに　1 期目の消費 \\(c_1 = w - a\\) がゼロか負値しかとれず，最適貯蓄あるいは最適消費が存在しなくなってしまうため．↩︎\nfminbound() のように数値計算によって方程式を解くアルゴリズムのことをソルバー (solver) と呼ぶ．↩︎\n図 5 では，アルゴリズムで求めた解のグラフが直線に見えるが，これは plot() の仕様によるもので，実際にはグリッドポイント上でしか最適貯蓄を計算していないことに注意．↩︎\n筆者は射影法を初めて学んだとき，未知の関数の形状をパラメータで規定し，ある判断基準に基づいてパラメータを推定するという点にどこか計量経済学のような雰囲気を感じた．↩︎\nチェビシェフ多項式 (Chebyshev polynomials) が基底関数として頻繁に用いられている．↩︎"
  },
  {
    "objectID": "terms.html",
    "href": "terms.html",
    "title": "Terms",
    "section": "",
    "text": "当サイトのコンテンツは、断りがある場合を除き CC-BY-NC 4.0 で提供されています。"
  },
  {
    "objectID": "terms.html#著作権",
    "href": "terms.html#著作権",
    "title": "Terms",
    "section": "",
    "text": "当サイトのコンテンツは、断りがある場合を除き CC-BY-NC 4.0 で提供されています。"
  },
  {
    "objectID": "terms.html#リンク",
    "href": "terms.html#リンク",
    "title": "Terms",
    "section": "リンク",
    "text": "リンク\n当サイトにリンクを行う場合の許可や連絡は不要です。\n\n\n\n\n\n\n\n当サイトのリンクやバナーから移動したサイトで提供される情報やサービス等について一切の責任を負いません。\n当サイトのコンテンツや情報については、可能なかぎり正確な情報を提供するように努めておりますが、正確性や安全性を保証するものではありません。"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "関連リンク",
    "section": "",
    "text": "Zenn では主にネットワーク科学関係の記事を書いています．\nどちらかというと理論的な側面が強いです．\n\n\n\n\n\n\n\nQiita では実装面で困ったことの備忘録や，ちょっとしたまとめを記載しています．"
  },
  {
    "objectID": "links.html#tech-blog",
    "href": "links.html#tech-blog",
    "title": "関連リンク",
    "section": "",
    "text": "Zenn では主にネットワーク科学関係の記事を書いています．\nどちらかというと理論的な側面が強いです．\n\n\n\n\n\n\n\nQiita では実装面で困ったことの備忘録や，ちょっとしたまとめを記載しています．"
  },
  {
    "objectID": "links.html#favorite",
    "href": "links.html#favorite",
    "title": "関連リンク",
    "section": "Favorite",
    "text": "Favorite\n\n\n\n\n\n\n\nMusic\n\n\n\n\n\n\n\n\nYouTube\n\n学術系\n\n大関真之の雑談方程式 - これって人生変えちゃう授業かも -\nAIcia Solid Project\n予備校のノリで学ぶ「大学の数学・物理」\n\n\n\nサイエンスコミュニケーション\n\nVeritasium\nLooking Glass Universe\n\n\n\n\n音楽系\n\nCateen かてぃん\nAnimenz Piano Sheets\nGrissini Project\n\n\n\nその他\n\nBappa Shota"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Recent Posts",
    "section": "",
    "text": "定量的マクロ経済学における数値計算の基礎\n\n\n\n\n\n\nMacroeconomics\n\n\nComputation\n\n\nPython\n\n\nSciPy\n\n\n\n近年，定量的マクロ経済学 (quantitative macroeconomics) と呼ばれる領域では，数値計算 (numerical computation) 技術が必須の分析手法となっている．本稿では２期間モデルというシンプルなモデルを用いて，ハンズオンで数値計算の基礎を学ぶ．扱う手法は，グリッドサーチ，最適化アルゴリズム，求根問題，射影法，内生的グリッド法（執筆中）である．\n\n\n\n\n\nOct 11, 2024\n\n\n岩永悠希\n\n\n\n\n\n\n\n\n\n\n\n\nMetropolis-Hastings アルゴリズム\n\n\nPython による実装\n\n\n\nBayesian\n\n\nMCMC\n\n\nSampling\n\n\nPython\n\n\n\nMCMC (Markov Chain Monte Carlo) とは，任意の確率分布からのサンプリングを実現するモンテカルロ法である． 本稿では MCMC の一つである Metropolis-Hastings (MH) 法を @chib1995 に沿って説明し，Python で実装することで MH 法への理解を深めたい． \n\n\n\n\n\nSep 27, 2024\n\n\n岩永悠希\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "index.html#hello",
    "href": "index.html#hello",
    "title": "Yuki IWANAGA | 岩永悠希",
    "section": "Hello!",
    "text": "Hello!\nI’m a 1st year Ph.D. student in economics supervised by Teruyoshi Kobayashi at the Kobe University in Hyogo, Japan.\nI study social and economic networks, where people’s behaviors affect one another, using game theory and statistical models.\nEmail: yuki.iwanaga136[at]gmail.com"
  },
  {
    "objectID": "index.html#fields-of-interest",
    "href": "index.html#fields-of-interest",
    "title": "Yuki IWANAGA | 岩永悠希",
    "section": "Fields of Interest",
    "text": "Fields of Interest"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Yuki IWANAGA | 岩永悠希",
    "section": "Education",
    "text": "Education\n\n M.A. in Economics, 2025\nKobe University, Japan\n\n\n B.A. in Arts, 2023\nKobe University, Japan"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Yuki IWANAGA | 岩永悠希",
    "section": "Experience",
    "text": "Experience\n\n Teaching Assistant\nKobe University, Japan\n\n\n Research Fellow, 2025.4 – present\nKobe University, Japan Supported by JST BOOST, Grant Number JPMJBS2410."
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Yuki IWANAGA | 岩永悠希",
    "section": "News",
    "text": "News\n\n\n[2025-11-05] Preprint: “Welfare bounds for linear-quadratic network games” with Teruyoshi Kobayashi.\n[2025-10-16] 神戸大学統合報告書2025の【学長×博士学生×若手研究者 座談会】に出演しました。\n[2025-09-30] Oral presentation at the 10th Annual International Conference in Hawaiʻi.\n[2025-04-03] 次世代ＡＩ人材育成プログラム (BOOST)に採択されました。"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "My research interests lie at the intersection of economics and network science. Although network science is a relatively new field that emerged in the years around the early 2000s, it has been applied across various domains with significant success. In economics, considering network structures has provided deeper insights in research areas such as input-output analysis, cascading failures in financial networks, and measuring peer effects.\nThe focus of my research is to develop a statistical model that identifies the mechanisms behind the formation of observed economic and social networks. A key concept in economic model building is microfoundation, and I am currently working on a model based on network game theory."
  },
  {
    "objectID": "research.html#about",
    "href": "research.html#about",
    "title": "Research",
    "section": "",
    "text": "My research interests lie at the intersection of economics and network science. Although network science is a relatively new field that emerged in the years around the early 2000s, it has been applied across various domains with significant success. In economics, considering network structures has provided deeper insights in research areas such as input-output analysis, cascading failures in financial networks, and measuring peer effects.\nThe focus of my research is to develop a statistical model that identifies the mechanisms behind the formation of observed economic and social networks. A key concept in economic model building is microfoundation, and I am currently working on a model based on network game theory."
  },
  {
    "objectID": "research.html#presentation",
    "href": "research.html#presentation",
    "title": "Research",
    "section": "Presentation",
    "text": "Presentation\n\nin English\n\nIwanaga and Kobayashi. Network Game Meets Machine Learning: A Microfounded Graphical Lasso. The 10th Annual International Conference in Hawaiʻi. 2025/9/30.\n\n\n\nin Japanese\n\nTBA. Nonlinear Physics Laboratory, Kyushu U. 2025/12/18."
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html",
    "href": "posts/2024/MCMC/metropolis-hastings.html",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "",
    "text": "$$\n$$"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html#モチベーション",
    "href": "posts/2024/MCMC/metropolis-hastings.html#モチベーション",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "モチベーション",
    "text": "モチベーション\nMCMC とは，任意の確率分布 \\(f(\\cdot)\\) を定常分布にもつマルコフ連鎖を生成することで，所望の分布 \\(f(\\cdot)\\) に従う乱数を生成するモンテカルロ法である．\nある確率分布に従う乱数が欲しい，あるいは確率分布を数値的に近似したいというシーンはしばしばある．\n例えば，ベイズ統計学ではデータ \\(D\\) から得た情報によって，パラメータ \\(\\theta\\) に対する信念とも言える事前分布 \\(p(\\theta)\\) を事後分布 \\(p(\\theta|D)\\) に更新し，この事後分布を使って推定を行う．\n\\[\np(\\theta|D) = \\frac{p(D|\\theta)p(\\theta)}{p(D)}\n\\]\nしかし，事後分布を解析的に導くことは，共役事前分布など特別な場合を除いて困難である．\nそこで，事後分布が定常分布となるような遷移確率（推移確率）を決めてパラメータについてのマルコフ連鎖 \\((\\theta_t)_{t\\geqslant 0}\\) を生成し，事後分布を数値的に近似することを考える．\nここで生じる問題は，どのようにしてパラメータについての遷移確率を決めれば良いかである．\n\n\n\n\n\n\nマルコフ連鎖については，Zenn に投稿しているマルコフ連鎖勉強ノートを参照．"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html#metropolis-hastings-アルゴリズム",
    "href": "posts/2024/MCMC/metropolis-hastings.html#metropolis-hastings-アルゴリズム",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "Metropolis-Hastings アルゴリズム",
    "text": "Metropolis-Hastings アルゴリズム\nMetropolis-Hastings (MH) 法は，目標分布 (target distribution) \\(\\pi(\\cdot)\\) を定常分布にもつマルコフ連鎖を生成するアルゴリズムの一つである．\n前述のベイズ統計学の例で言うと，事後分布 \\(p(\\theta|D)\\) が目標分布 \\(\\pi(\\theta)\\) ということになる． 本稿では引き続きこの例を使用し，パラメータ \\(\\theta \\in \\Theta \\subset \\mathbb{R}^d\\) の従う分布 \\(\\pi(\\theta)\\) を目標分布だと考えて議論を進める．\n\n提案分布の導入\nマルコフ連鎖は，状態空間 (state space) と状態間の遷移確率で規定される． 現時点でわかっていることは，パラメータ \\(\\theta\\) が状態空間 \\(\\Theta\\) の一つの状態を表すということだけで，どのような遷移確率で状態遷移するかは未知である．\nそこで，状態 \\(\\theta\\) の下での提案分布 \\(q(\\theta, \\theta')\\) を適当に導入する． ただし，\\(\\int_\\Theta q(\\theta, \\theta') d\\theta' = 1\\)である． 提案分布はマルコフ連鎖 \\((\\theta_t)\\) が状態 \\(\\theta\\) にあるとき，来期の状態 \\(\\theta'\\) が条件付き確率 \\(q(\\theta, \\theta')\\) で決まることを意味する．\nもし提案分布 \\(q(\\theta, \\theta')\\) が詳細釣り合い条件\n\\[\n\\pi(\\theta)q(\\theta, \\theta') = \\pi(\\theta')q(\\theta', \\theta) \\quad \\forall \\theta, \\theta' \\in \\Theta\n\\tag{1}\\]\nを満たすなら，目標分布 \\(\\pi(\\cdot)\\) を定常分布にもつマルコフ連鎖の遷移確率を得たことになるので，\\(q(\\theta, \\theta')\\) を用いてサンプリングすれば良い． 実際，式 1 の両辺を \\(\\theta'\\) について積分すれば，\\(\\pi(\\cdot)\\) が定常分布であることがわかる：\n\\[\n\\pi(\\theta) = \\int_\\Theta \\pi(\\theta')q(\\theta', \\theta) d\\theta'.\n\\]\nしかし，\\(q(\\theta, \\theta')\\) は適当に設定した分布なので 式 1 は一般には成り立たない． ここで，一般性を失わずに\n\\[\n\\pi(\\theta)q(\\theta, \\theta') &gt; \\pi(\\theta')q(\\theta', \\theta)\n\\tag{2}\\]\nと仮定する． 目標分布 \\(\\pi(\\theta)\\) を状態 \\(\\theta\\) にある人の割合と思えば，式 2 は状態 \\(\\theta\\) から \\(\\theta'\\) に移動する人の割合が，逆に \\(\\theta'\\) から \\(\\theta\\) に移動する人の割合よりも大きいということを表している．\n\n\n状態遷移の制限\n詳細釣り合い条件（式 1）は，両者の割合が同じであってほしいという要請なので，人の移動に交通規制をかけて状態間の移動人数が釣り合うようにしよう． 具体的には，状態 \\(\\theta\\) から \\(\\theta'\\) への移動を制限する確率 \\(\\alpha(\\theta, \\theta') &lt; 1\\) を導入し，\\(\\theta\\) から \\(\\theta'\\) へ移動する人の数を減らせば良い． この任意の2点間の移動を制限する確率 \\(\\alpha(\\cdot, \\cdot) \\in [0,1]\\) をここでは交通規制率と呼ぶことにする1．\n\n\n\n\n\n\nこの時点で考えている問題が，どのような提案分布を設定すべきかという問題から交通規制率を求める問題に変化したことに注意．\n\n\n\n交通規制率を導入すれば，状態 \\(\\theta\\) と \\(\\theta' \\neq \\theta\\) の間の移動は\n\\[\n\\begin{cases}\np_\\text{MH}(\\theta, \\theta') \\equiv q(\\theta, \\theta')\\alpha(\\theta, \\theta') \\\\\np_\\text{MH}(\\theta', \\theta) = q(\\theta', \\theta)\\alpha(\\theta', \\theta)\n\\end{cases}\n\\qquad (\\theta \\neq \\theta')\n\\tag{3}\\]\nに従って行われることになる． 式 2 は \\(\\theta'\\) から \\(\\theta\\) への移動数が不十分だと主張しているので，この方向の移動については規制をかけず \\(\\alpha(\\theta', \\theta) = 1\\) と設定する．\n以上のように \\(\\theta\\) から \\(\\theta'\\) への移動には規制をかけ，\\(\\theta'\\) から \\(\\theta\\) の移動を全て許可すれば，詳細釣り合い条件\n\\[\n\\pi(\\theta)p_\\text{MH}(\\theta, \\theta') = \\pi(\\theta')p_\\text{MH}(\\theta', \\theta)\n\\tag{4}\\]\nが成り立つので，式 3 を使って書き下すと次式を得る：\n\\[\n\\begin{aligned}\n\\pi(\\theta)q(\\theta, \\theta')\\alpha(\\theta, \\theta') &= \\pi(\\theta')q(\\theta', \\theta)\\alpha(\\theta', \\theta) \\\\\n&= \\pi(\\theta')q(\\theta', \\theta).\n\\end{aligned}\n\\]\nこれを \\(\\alpha(\\theta, \\theta')\\) について解けば，\n\\[\n\\alpha(\\theta, \\theta') =\n\\frac{\\pi(\\theta')q(\\theta', \\theta)}{\\pi(\\theta)q(\\theta, \\theta')}\n\\]\nと交通規制率を求めることができる． この \\(\\alpha(\\theta, \\theta')\\) は 式 2 の大小関係の下で導出されたが，不等号が逆向きの場合も同様にして求めることができる．\n一度ここまでの議論をまとめよう．\n\n\n\n\n\n\n\n目標分布 \\(\\pi(\\theta)\\) を定常分布にもつマルコフ連鎖 \\((\\theta_t)\\) の遷移確率が未知なので，代わりに提案分布 \\(q(\\theta, \\theta')\\) を導入した．\n提案分布が詳細釣り合い条件（式 1）を直接満たすとは限らないので，所与の提案分布に対して詳細釣り合い条件が成り立つように交通規制率を次式で定めた2．\n\n\\[\n\\alpha(\\theta, \\theta') =\n\\min\\left\\{ 1, \\frac{\\pi(\\theta')q(\\theta', \\theta)}{\\pi(\\theta)q(\\theta, \\theta')} \\right\\}\n\\qquad (\\theta \\neq \\theta')\n\\tag{5}\\]\n\n\n\n\n\n遷移確率の定式化\nこれまでの議論では，状態遷移 \\(\\theta\\to\\theta'\\) について \\(\\theta' \\neq \\theta\\) であることを暗に仮定していた．MH 法の遷移確率を定式化するには，状態が \\(\\theta\\) にとどまるケース \\(\\theta\\to\\theta\\) も考える必要がある．\n状態が \\(\\theta\\) にとどまる確率は次式で与えられる．\n\\[\n\\begin{aligned}\nr(\\theta)\n&= 1 - \\int_\\Theta p_\\text{MH}(\\theta, \\theta') d\\theta'\\\\\n&= 1 - \\int_\\Theta q(\\theta, \\theta')\\alpha(\\theta, \\theta') d\\theta'\n\\end{aligned}\n\\tag{6}\\]\n式 6 を用いると MH 法の遷移確率 \\(P_\\text{MH}(\\theta, \\theta')\\) は，\n\\[\n\\begin{aligned}\nP_\\text{MH}(\\theta, \\theta')\n&= p_\\text{MH}(\\theta, \\theta') + \\delta(\\theta' -\\theta)r(\\theta) \\\\\n&= q(\\theta, \\theta')\\alpha(\\theta, \\theta') + \\delta(\\theta' -\\theta)r(\\theta)\n\\end{aligned}\n\\tag{7}\\]\nである． ただし，\\(\\delta(x)\\) はディラックのデルタ関数である3．\n\n\n\n\n\n\n命題\n\n\n\n式 7 で与えられるMH 法の遷移確率 \\(P_\\text{MH}(\\theta, \\theta')\\) の下で，目標分布 \\(\\pi(\\cdot)\\) は定常分布である． すなわち，\n\\[\n\\int_\\Theta \\pi(\\theta)P_\\text{MH}(\\theta, \\theta') d\\theta = \\pi(\\theta') \\qquad \\forall\\theta,\\theta'\\in\\Theta.\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\n\n\\(\\theta,\\theta'\\in\\Theta\\) を任意にとる． 式 4 を用いると次式が成り立つ．\n\\[\n\\begin{aligned}\n\\int_\\Theta \\pi(\\theta)P_\\text{MH}(\\theta, \\theta') d\\theta\n&= \\int_\\Theta \\pi(\\theta)\\left[ p_\\text{MH}(\\theta, \\theta') + \\delta(\\theta' -\\theta)r(\\theta) \\right] d\\theta \\\\\n&= \\int_\\Theta \\textcolor{salmon}{\\pi(\\theta)p_\\text{MH}(\\theta, \\theta')}d\\theta + \\int_\\Theta \\pi(\\theta)\\delta(\\theta' -\\theta)r(\\theta)d\\theta \\\\\n&= \\int_\\Theta \\textcolor{salmon}{\\pi(\\theta')p_\\text{MH}(\\theta', \\theta)}d\\theta + \\pi(\\theta')r(\\theta') \\\\\n&= \\pi(\\theta')\\int_\\Theta p_\\text{MH}(\\theta', \\theta)d\\theta + \\pi(\\theta')\\left[1 - \\int_\\Theta p_\\text{MH}(\\theta', \\theta) d\\theta\\right] \\\\\n&= \\pi(\\theta').\n\\end{aligned}\n\\]\n\n\n\n\n\nMH アルゴリズム\nMH 法をアルゴリズムとして書き下すと，次のようになる．\n\n\n\n\n\n\nPseudocode for Metropolis Hastings method\n\n\n\nInput: The number of samples \\(N\\) and starting point \\(\\theta_0\\).\n\nfor n = 1,…, N do\n Propose \\(\\theta' \\sim q(\\theta_{n-1}, \\theta')\\).\n Compute the acceptance ratio given by\n\n\\[\n\\alpha(\\theta_{n-1}, \\theta') =\n\\min\\left\\{ 1, \\frac{\\pi(\\theta')q(\\theta', \\theta_{n-1})}{\\pi(\\theta_{n-1})q(\\theta_{n-1}, \\theta')} \\right\\}.\n\\]\n\n Draw \\(u \\sim \\text{Uniform}[0, 1)\\).\n If \\(u &lt; \\alpha(\\theta_{n-1}, \\theta')\\), then set \\(\\theta_n = \\theta'\\).\n Otherwise reject the proposal \\(\\theta'\\) and set \\(\\theta_n = \\theta_{n-1}\\).\nend for\nDiscard first burnin samples and return the remaining samples.\n\n\n\n特に，提案分布が \\(q(\\theta_{n-1}, \\theta') = q(\\theta', \\theta_{n-1})\\) と対称的である場合は acceptance ratio が\n\\[\n\\alpha(\\theta_{n-1}, \\theta') =\n\\min\\left\\{ 1, \\frac{\\pi(\\theta')}{\\pi(\\theta_{n-1})} \\right\\}\n\\]\nと簡単になり，解釈もしやすくなる．\nつまり，\\(\\theta_{n-1}\\to\\theta'\\) の状態遷移で目標分布 \\(\\pi(\\cdot)\\) の山を登る方向の移動\n\\[\n\\pi(\\theta_{n-1}) \\leqslant \\pi(\\theta') \\;\\mathrm{iff}\\;\n\\frac{\\pi(\\theta')}{\\pi(\\theta_{n-1})} \\geqslant 1\n\\]\nは確率 \\(1\\) で許可されるが，逆に山を降る方向の移動\n\\[\n\\pi(\\theta_{n-1}) &gt; \\pi(\\theta') \\;\\mathrm{iff}\\;\n\\frac{\\pi(\\theta')}{\\pi(\\theta_{n-1})} &lt; 1\n\\]\nについては，確率 \\(\\alpha(\\theta_{n-1}, \\theta') = \\pi(\\theta') / \\pi(\\theta_{n-1})\\) で移動が許可される．\n\n\n\nSource: Chib and Greenberg (1995)\n\n\nChib and Greenberg (1995) の図を借りると，\\(\\pi(\\cdot)\\) という山で現在地 \\(x\\) の標高よりも高い地点 \\(y_1\\) に登る提案は 100% 受け入れられ，標高の低い地点 \\(y_2\\) に移動する提案は \\(\\alpha(x, y_2)\\) で確率的に受け入れられるということだ．"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html#python-による実装",
    "href": "posts/2024/MCMC/metropolis-hastings.html#python-による実装",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "Python による実装",
    "text": "Python による実装\n上記のMHアルゴリズムを metropolis_hastings() として実装する． 提案分布には平均 \\(\\theta_{t-1}\\)，標準偏差 proposal_std を持つ対称的な正規分布を使用する． したがって，acceptance ratio は目標分布の比に一致する．\nここでは，標準正規分布を目標分布とし，確率密度\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2}\\right)\n\\]\nからMH法によってサンプリングを行う関数を実装する．\n\n実装\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef standard_normal(x):\n    \"\"\"目標分布 f(x) に比例する関数。ここでは標準正規分布を使用。\"\"\"\n    return np.exp(-0.5 * x**2)  # 正規化定数は除く\n\ndef metropolis_hastings(N, x_0, proposal_std):\n    \"\"\"\n    Metropolis-Hastings アルゴリズムによるサンプリング\n    \n    N:            サンプル数\n    x_0:          初期値\n    proposal_std: 提案分布の標準偏差\n    \"\"\"\n\n    samples =[]\n    x = x_0\n\n    for _ in range(N):\n        x_new = np.random.normal(loc=x, scale=proposal_std)\n\n        acceptance_ratio = standard_normal(x_new) / standard_normal(x)\n\n        if np.random.rand() &lt; acceptance_ratio:\n            x = x_new\n\n        samples.append(x)\n\n    return samples\n\n\n\nサンプリング\nmetropolis_hastings() を使って標準正規分布から N=10000 個サンプリングを行い，そのトレースプロットを描いてみる． 初期値は x_0=0 に設定する．\n\n# サンプリング\nsamples1 = metropolis_hastings(N=10000, x_0=0, proposal_std=1.0)\n\n# トレースプロット\nplt.figure(figsize=(8, 4))\nplt.plot(samples1, lw=0.8)\nplt.title('Trace Plot of Samples')\nplt.xlabel('Iteration')\nplt.ylabel('Sample Value')\nplt.show()\n\n\n\n\n\n\n\n\nチェーンの最初の部分は初期値依存性があるので，サンプルの最初の 2000 個を burnin として捨て，残りの 8000 個のヒストグラムと目標分布を重ねて描いてみる．\n\n# サンプルと目標分布のプロット\nplt.figure(figsize=(8, 4))\nplt.hist(samples1[2000:], bins=50, density=True, alpha=0.8, color='#78C2AD', label='Sampled distribution')\nx = np.linspace(-4, 4, 1000)\nplt.plot(x, 1/np.sqrt(2*np.pi) * np.exp(-x**2 / 2), '#FF7A72', lw=2, label='Target distribution N(0,1)')\nplt.title('Metropolis-Hastings Sampling')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nおおよそ目標分布（赤線）を数値的に近似できている様子が見て取れる． 次に，初期値を x_0=3 に変え， N=100000 個サンプリングを行ってみる． サンプルサイズが増えるので，ヒストグラムはより赤線に近い形になるはずである．\n\n# 初期値とサンプルサイズを変えてみる\nsamples2 = metropolis_hastings(N=100000, x_0=3, proposal_std=1.0)\n\n# トレースプロット\nplt.figure(figsize=(10, 4))\nplt.plot(samples2, lw=0.5)\nplt.title('Trace Plot of Samples')\nplt.xlabel('Iteration')\nplt.ylabel('Sample Value')\nplt.show()\n\n\n\n\n\n\n\n\n\n# サンプルと目標分布のプロット\nplt.figure(figsize=(8, 4))\nplt.hist(samples2, bins=50, density=True, alpha=0.8, color='#78C2AD', label='Sampled distribution')\nx = np.linspace(-4, 4, 1000)\nplt.plot(x, 1/np.sqrt(2*np.pi) * np.exp(-x**2 / 2), '#FF7A72', lw=2, label='Target distribution N(0,1)')\nplt.title('Metropolis-Hastings Sampling')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nおまけ：R のコード\n上記の一連の流れを以下の R コードで行うこともできる．\n```{r}\n# 目標分布（標準正規分布）\nstandard_norm &lt;- function(x) {\n    return(exp(-0.5 * x^2))\n}\n\n# MH アルゴリズム\nmetropolis_hastings &lt;- function(x_0, N, proposal_std) {\n    x &lt;- x_0\n    samples &lt;- numeric(N)\n\n    for (n in 1:N) {\n        x_new &lt;- rnorm(1, mean = x, sd = proposal_std)\n\n        acceptance_ratio &lt;- standard_norm(x_new) / standard_norm(x)\n\n        if (runif(1) &lt; acceptance_ratio) {\n            x &lt;- x_new\n        }\n\n        samples[n] &lt;- x\n    }\n    return(samples)\n}\n\n# MH法によるサンプリング\nsamples &lt;- metropolis_hastings(0, 10000, 1.0)\n\n# トレースプロット\nplot(samples, type=\"l\", col=\"blue\", \n    main=\"Trace Plot of MH Sampling\", \n    xlab=\"Iteration\", ylab=\"Sample Value\")\n\n# サンプルのヒストグラムとターゲット分布のプロット\nhist(samples, breaks = 50, probability = TRUE, col = \"lightblue\", \n     main = \"Metropolis-Hastings Sampling\", xlab = \"x\")\n\n# 標準正規分布を重ねてプロット\ncurve(dnorm(x, mean = 0, sd = 1), col = \"red\", lwd = 2, add = TRUE)\n```"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html#footnotes",
    "href": "posts/2024/MCMC/metropolis-hastings.html#footnotes",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n一般には採択比率 (acceptance ratio) や採択確率 (acceptance probability) などと呼ばれる．↩︎\n式 2 の不等号の向きがどちらの場合であっても対応できるように \\(\\min\\{\\}\\) を使用．流出する人の数（分母）が流入する人の数（分子）よりも大きい場合のみ交通規制をかけるということ．↩︎\n\\(x=0\\) のとき \\(1\\) をとり，それ以外の \\(x\\) で \\(0\\) をとる関数．↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Zenn では主にネットワーク科学関係の記事を書いています．\nどちらかというと理論的な側面が強いです．\n\n\n\n\n\n\n\nQiita では実装面で困ったことの備忘録や，ちょっとしたまとめを記載しています．"
  },
  {
    "objectID": "about.html#tech-blog",
    "href": "about.html#tech-blog",
    "title": "About",
    "section": "Tech Blog",
    "text": "Tech Blog\n\n\n\n\n\n\n\n\n\n\n\nZenn では主にネットワーク科学関係の記事を書いています．\nどちらかというと理論的な側面が強いです．\n\n\n\n\n\n\n\nQiita では実装面で困ったことの備忘録や，ちょっとしたまとめを記載しています．"
  },
  {
    "objectID": "about.html#favorite",
    "href": "about.html#favorite",
    "title": "About",
    "section": "Favorite",
    "text": "Favorite\n\n\n\n\n\n\n\nMusic\n\n\n\n\n\n\n\n\nYouTube\n\n学術系\n\n大関真之の雑談方程式 - これって人生変えちゃう授業かも -\nAIcia Solid Project\n予備校のノリで学ぶ「大学の数学・物理」\n\n\n\nサイエンスコミュニケーション\n\nVeritasium\nLooking Glass Universe\n\n\n\n\n音楽系\n\nCateen かてぃん\nAnimenz Piano Sheets\nGrissini Project\n\n\n\nその他\n\nBappa Shota"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\n\n M.A. in Economics, 2025\nKobe University, Japan\n\n\n B.A. in Arts, 2023\nKobe University, Japan"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\n\n Teaching Assistant\nKobe University, Japan\n\n\n Research Fellow, 2025.4 – present\nKobe University, Japan Supported by JST BOOST, Grant Number JPMJBS2410."
  },
  {
    "objectID": "research.html#preprints",
    "href": "research.html#preprints",
    "title": "Research",
    "section": "Preprints",
    "text": "Preprints\n\n“Welfare bounds for linear-quadratic network games” with Teruyoshi Kobayashi, 2025."
  }
]