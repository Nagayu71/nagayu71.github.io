[
  {
    "objectID": "terms.html",
    "href": "terms.html",
    "title": "Terms",
    "section": "",
    "text": "当サイトのコンテンツは、断りがある場合を除き CC-BY-NC 4.0 で提供されています。"
  },
  {
    "objectID": "terms.html#著作権",
    "href": "terms.html#著作権",
    "title": "Terms",
    "section": "",
    "text": "当サイトのコンテンツは、断りがある場合を除き CC-BY-NC 4.0 で提供されています。"
  },
  {
    "objectID": "terms.html#リンク",
    "href": "terms.html#リンク",
    "title": "Terms",
    "section": "リンク",
    "text": "リンク\n当サイトにリンクを行う場合の許可や連絡は不要です。\n\n\n\n\n\n\n\n当サイトのリンクやバナーから移動したサイトで提供される情報やサービス等について一切の責任を負いません。\n当サイトのコンテンツや情報については、可能なかぎり正確な情報を提供するように努めておりますが、正確性や安全性を保証するものではありません。"
  },
  {
    "objectID": "index.html#hello",
    "href": "index.html#hello",
    "title": "Yuki Iwanaga | 岩永悠希",
    "section": "Hello!",
    "text": "Hello!\nI’m a 2nd year master’s Econ student supervised by Teruyoshi Kobayashi at the Kobe University in Hyogo, Japan."
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "Yuki Iwanaga | 岩永悠希",
    "section": "Interests",
    "text": "Interests\n\nCollective Behavior\nNetwork Science\nNetwork Games\n\nStrategic network formation\nEconometric network formation models\n\nMacroeconomics\nStatistical Physics\nBayesian Modeling\nHistory of Science"
  },
  {
    "objectID": "index.html#research",
    "href": "index.html#research",
    "title": "Yuki Iwanaga | 岩永悠希",
    "section": "Research",
    "text": "Research\nMy research interests lie at the intersection of economics and network science. Although network science is a relatively new field that emerged in the years around the early 2000s, it has been applied across various domains with significant success. In economics, considering network structures has provided deeper insights in research areas such as input-output analysis, cascading failures in financial networks, and measuring peer effects.\nThe focus of my research is to develop a statistical model that identifies the mechanisms behind the formation of observed economic and social networks. A key concept in economic model building is microfoundation, and I am currently working on a model based on network game theory."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Yuki Iwanaga | 岩永悠希",
    "section": "Education",
    "text": "Education\n\n M.A. in Economics, 2025 (expected)\nKobe University, Japan\n\n\n B.A. in Arts, 2023\nKobe University, Japan"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Yuki Iwanaga | 岩永悠希",
    "section": "Experience",
    "text": "Experience\n\n Teaching Assistant\nKobe University, Japan\n\n\n Data Analyst\nmerchu inc. Long-term internship"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "関連リンク",
    "section": "",
    "text": "Zenn では主にネットワーク科学関係の記事を書いています．\nどちらかというと理論的な側面が強いです．\n\n\n\n\n\n\n\nQiita では実装面で困ったことの備忘録や，ちょっとしたまとめを記載しています．"
  },
  {
    "objectID": "links.html#tech-blog",
    "href": "links.html#tech-blog",
    "title": "関連リンク",
    "section": "",
    "text": "Zenn では主にネットワーク科学関係の記事を書いています．\nどちらかというと理論的な側面が強いです．\n\n\n\n\n\n\n\nQiita では実装面で困ったことの備忘録や，ちょっとしたまとめを記載しています．"
  },
  {
    "objectID": "links.html#favorite",
    "href": "links.html#favorite",
    "title": "関連リンク",
    "section": "Favorite",
    "text": "Favorite\n\n\n\n\n\n\n\nMusic\n\n\n\n\n\n\n\n\nYouTube\n\n予備校のノリで学ぶ「大学の数学・物理」\nAnimenz Piano Sheets\nBappa Shota"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Recent Posts",
    "section": "",
    "text": "Metropolis-Hastings アルゴリズム\n\n\nPython による実装\n\n\n\nBayesian\n\n\nMCMC\n\n\nSampling\n\n\nPython\n\n\n\nMCMC (Markov Chain Monte Carlo) とは，任意の確率分布からのサンプリングを実現するモンテカルロ法である． 本稿では MCMC の一つである Metropolis-Hastings (MH) 法を @chib1995 に沿って説明し，Python で実装することで MH 法への理解を深めたい． \n\n\n\n\n\nSep 27, 2024\n\n\n岩永悠希\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html",
    "href": "posts/2024/MCMC/metropolis-hastings.html",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "",
    "text": "MCMC とは，任意の確率分布 \\(f(\\cdot)\\) を定常分布にもつマルコフ連鎖を生成することで，所望の分布 \\(f(\\cdot)\\) に従う乱数を生成するモンテカルロ法である．\nある確率分布に従う乱数が欲しい，あるいは確率分布を数値的に近似したいというシーンはしばしばある．\n例えば，ベイズ統計学ではデータ \\(D\\) から得た情報によって，パラメータ \\(\\theta\\) に対する信念とも言える事前分布 \\(p(\\theta)\\) を事後分布 \\(p(\\theta|D)\\) に更新し，この事後分布を使って推定を行う．\n\\[\np(\\theta|D) = \\frac{p(D|\\theta)p(\\theta)}{p(D)}\n\\]\nしかし，事後分布を解析的に導くことは，共役事前分布など特別な場合を除いて困難である．\nそこで，事後分布が定常分布となるような遷移確率（推移確率）を決めてパラメータについてのマルコフ連鎖 \\((\\theta_t)_{t\\geqslant 0}\\) を生成し，事後分布を数値的に近似することを考える．\nここで生じる問題は，どのようにしてパラメータについての遷移確率を決めれば良いかである．\n\n\n\n\n\n\nマルコフ連鎖については，Zenn に投稿しているマルコフ連鎖勉強ノートを参照．"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html#モチベーション",
    "href": "posts/2024/MCMC/metropolis-hastings.html#モチベーション",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "",
    "text": "MCMC とは，任意の確率分布 \\(f(\\cdot)\\) を定常分布にもつマルコフ連鎖を生成することで，所望の分布 \\(f(\\cdot)\\) に従う乱数を生成するモンテカルロ法である．\nある確率分布に従う乱数が欲しい，あるいは確率分布を数値的に近似したいというシーンはしばしばある．\n例えば，ベイズ統計学ではデータ \\(D\\) から得た情報によって，パラメータ \\(\\theta\\) に対する信念とも言える事前分布 \\(p(\\theta)\\) を事後分布 \\(p(\\theta|D)\\) に更新し，この事後分布を使って推定を行う．\n\\[\np(\\theta|D) = \\frac{p(D|\\theta)p(\\theta)}{p(D)}\n\\]\nしかし，事後分布を解析的に導くことは，共役事前分布など特別な場合を除いて困難である．\nそこで，事後分布が定常分布となるような遷移確率（推移確率）を決めてパラメータについてのマルコフ連鎖 \\((\\theta_t)_{t\\geqslant 0}\\) を生成し，事後分布を数値的に近似することを考える．\nここで生じる問題は，どのようにしてパラメータについての遷移確率を決めれば良いかである．\n\n\n\n\n\n\nマルコフ連鎖については，Zenn に投稿しているマルコフ連鎖勉強ノートを参照．"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html#metropolis-hastings-algorithm",
    "href": "posts/2024/MCMC/metropolis-hastings.html#metropolis-hastings-algorithm",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "Metropolis-Hastings Algorithm",
    "text": "Metropolis-Hastings Algorithm\nMetropolis-Hastings (MH) 法は，目標分布 (target distribution) \\pi(\\cdot) を定常分布にもつマルコフ連鎖を生成するアルゴリズムの一つである．\n前述のベイズ統計学の例で言うと，事後分布 p(\\theta|D) が目標分布 \\pi(\\theta) ということになる． 本稿では引き続きこの例を使用し，パラメータ \\theta \\in \\Theta \\subset \\R^d の従う分布 \\pi(\\theta) を目標分布だと考えて議論を進める．\n\n提案分布の導入\nマルコフ連鎖は，状態空間 (state space) と状態間の遷移確率で規定される． 現時点でわかっていることは，パラメータ \\theta が状態空間 \\Theta の一つの状態を表すということだけで，どのような遷移確率で状態遷移するかは未知である．\nそこで，状態 \\theta の下での提案分布 q(\\theta, \\theta') を適当に導入する． ただし，\\int_\\Theta q(\\theta, \\theta') d\\theta' = 1である． 提案分布はマルコフ連鎖 (\\theta_t) が状態 \\theta にあるとき，来期の状態 \\theta' が条件付き確率 q(\\theta, \\theta') で決まることを意味する．\nもし提案分布 q(\\theta, \\theta') が詳細釣り合い条件\n\n\\pi(\\theta)q(\\theta, \\theta') = \\pi(\\theta')q(\\theta', \\theta) \\quad \\forall \\theta, \\theta' \\in \\Theta\n\\tag{1}\nを満たすなら，目標分布 \\pi(\\cdot) を定常分布にもつマルコフ連鎖の遷移確率を得たことになるので，q(\\theta, \\theta') を用いてサンプリングすれば良い． 実際，式 1 の両辺を \\theta' について積分すれば，\\pi(\\cdot) が定常分布であることがわかる：\n\n\\pi(\\theta) = \\int_\\Theta \\pi(\\theta')q(\\theta', \\theta) d\\theta'.\n\nしかし，q(\\theta, \\theta') は適当に設定した分布なので 式 1 は一般には成り立たない． ここで，一般性を失わずに\n\n\\pi(\\theta)q(\\theta, \\theta') &gt; \\pi(\\theta')q(\\theta', \\theta)\n\\tag{2}\nと仮定する． 目標分布 \\pi(\\theta) を状態 \\theta にある人の割合と思えば，式 2 は状態 \\theta から \\theta' に移動する人の割合が，逆に \\theta' から \\theta に移動する人の割合よりも大きいということを表している．\n\n\n状態遷移の制限\n詳細釣り合い条件（式 1）は，両者の割合が同じであってほしいという要請なので，人の移動に交通規制をかけて状態間の移動人数が釣り合うようにしよう． 具体的には，状態 \\theta から \\theta' への移動を制限する確率 \\alpha(\\theta, \\theta') &lt; 1 を導入し，\\theta から \\theta' へ移動する人の数を減らせば良い． この任意の2点間の移動を制限する確率 \\alpha(\\cdot, \\cdot) \\in [0,1] をここでは交通規制率と呼ぶことにする1．\n\n\n\n\n\n\nこの時点で考えている問題が，どのような提案分布を設定すべきかという問題から交通規制率を求める問題に変化したことに注意．\n\n\n\n交通規制率を導入すれば，状態 \\theta と \\theta' \\neq \\theta の間の移動は\n\n\\begin{cases}\np_\\text{MH}(\\theta, \\theta') \\equiv q(\\theta, \\theta')\\alpha(\\theta, \\theta') \\\\\np_\\text{MH}(\\theta', \\theta) = q(\\theta', \\theta)\\alpha(\\theta', \\theta)\n\\end{cases}\n\\qquad (\\theta \\neq \\theta')\n\\tag{3}\nに従って行われることになる． 式 2 は \\theta' から \\theta への移動数が不十分だと主張しているので，この方向の移動については規制をかけず \\alpha(\\theta', \\theta) = 1 と設定する．\n以上のように \\theta から \\theta' への移動には規制をかけ，\\theta' から \\theta の移動を全て許可すれば，詳細釣り合い条件\n\n\\pi(\\theta)p_\\text{MH}(\\theta, \\theta') = \\pi(\\theta')p_\\text{MH}(\\theta', \\theta)\n\\tag{4}\nが成り立つので，式 3 を使って書き下すと次式を得る：\n\n\\begin{aligned}\n\\pi(\\theta)q(\\theta, \\theta')\\alpha(\\theta, \\theta') &= \\pi(\\theta')q(\\theta', \\theta)\\alpha(\\theta', \\theta) \\\\\n&= \\pi(\\theta')q(\\theta', \\theta).\n\\end{aligned}\n\nこれを \\alpha(\\theta, \\theta') について解けば，\n\n\\alpha(\\theta, \\theta') =\n\\frac{\\pi(\\theta')q(\\theta', \\theta)}{\\pi(\\theta)q(\\theta, \\theta')}\n\nと交通規制率を求めることができる． この \\alpha(\\theta, \\theta') は 式 2 の大小関係の下で導出されたが，不等号が逆向きの場合も同様にして求めることができる．\n一度ここまでの議論をまとめよう．\n\n\n\n\n\n\n\n目標分布 \\pi(\\theta) を定常分布にもつマルコフ連鎖 (\\theta_t) の遷移確率が未知なので，代わりに提案分布 q(\\theta, \\theta') を導入した．\n提案分布が詳細釣り合い条件（式 1）を直接満たすとは限らないので，所与の提案分布に対して詳細釣り合い条件が成り立つように交通規制率を次式で定めた2．\n\n\n\\alpha(\\theta, \\theta') =\n\\min\\left\\{ 1, \\frac{\\pi(\\theta')q(\\theta', \\theta)}{\\pi(\\theta)q(\\theta, \\theta')} \\right\\}\n\\qquad (\\theta \\neq \\theta')\n\\tag{5}\n\n\n\n\n\n遷移確率の定式化\nこれまでの議論では，状態遷移 \\theta\\to\\theta' について \\theta' \\neq \\theta であることを暗に仮定していた．MH 法の遷移確率を定式化するには，状態が \\theta にとどまるケース \\theta\\to\\theta も考える必要がある．\n状態が \\theta にとどまる確率は次式で与えられる．\n\n\\begin{aligned}\nr(\\theta)\n&= 1 - \\int_\\Theta p_\\text{MH}(\\theta, \\theta') d\\theta'\\\\\n&= 1 - \\int_\\Theta q(\\theta, \\theta')\\alpha(\\theta, \\theta') d\\theta'\n\\end{aligned}\n\\tag{6}\n式 6 を用いると MH 法の遷移確率 P_\\text{MH}(\\theta, \\theta') は，\n\n\\begin{aligned}\nP_\\text{MH}(\\theta, \\theta')\n&= p_\\text{MH}(\\theta, \\theta') + \\delta(\\theta' -\\theta)r(\\theta) \\\\\n&= q(\\theta, \\theta')\\alpha(\\theta, \\theta') + \\delta(\\theta' -\\theta)r(\\theta)\n\\end{aligned}\n\\tag{7}\nである． ただし，\\delta(x) はディラックのデルタ関数である3．\n\n\n\n\n\n\n命題\n\n\n\n式 7 で与えられるMH 法の遷移確率 P_\\text{MH}(\\theta, \\theta') の下で，目標分布 \\pi(\\cdot) は定常分布である． すなわち，\n\n\\int_\\Theta \\pi(\\theta)P_\\text{MH}(\\theta, \\theta') d\\theta = \\pi(\\theta') \\qquad \\forall\\theta,\\theta'\\in\\Theta.\n\n\n\n\n\n\n\n\n\n証明\n\n\n\n\n\n\\theta,\\theta'\\in\\Theta を任意にとる． 式 4 を用いると次式が成り立つ．\n\n\\begin{aligned}\n\\int_\\Theta \\pi(\\theta)P_\\text{MH}(\\theta, \\theta') d\\theta\n&= \\int_\\Theta \\pi(\\theta)\\left[ p_\\text{MH}(\\theta, \\theta') + \\delta(\\theta' -\\theta)r(\\theta) \\right] d\\theta \\\\\n&= \\int_\\Theta \\textcolor{salmon}{\\pi(\\theta)p_\\text{MH}(\\theta, \\theta')}d\\theta + \\int_\\Theta \\pi(\\theta)\\delta(\\theta' -\\theta)r(\\theta)d\\theta \\\\\n&= \\int_\\Theta \\textcolor{salmon}{\\pi(\\theta')p_\\text{MH}(\\theta', \\theta)}d\\theta + \\pi(\\theta')r(\\theta') \\\\\n&= \\pi(\\theta')\\int_\\Theta p_\\text{MH}(\\theta', \\theta)d\\theta + \\pi(\\theta')\\left[1 - \\int_\\Theta p_\\text{MH}(\\theta', \\theta) d\\theta\\right] \\\\\n&= \\pi(\\theta').\n\\end{aligned}\n\n\n\n\n\n\nMH アルゴリズム\nMH 法をアルゴリズムとして書き下すと，次のようになる．\n\n\n\n\n\n\nPseudocode for Metropolis Hastings method\n\n\n\nInput: The number of samples N and starting point \\theta_0.\n\nfor n = 1,…, N do\n Propose \\theta' \\sim q(\\theta_{n-1}, \\theta').\n Compute the acceptance ratio given by\n\n\n\\alpha(\\theta_{n-1}, \\theta') =\n\\min\\left\\{ 1, \\frac{\\pi(\\theta')q(\\theta', \\theta_{n-1})}{\\pi(\\theta_{n-1})q(\\theta_{n-1}, \\theta')} \\right\\}.\n\n\n Draw u \\sim \\text{Uniform}[0, 1).\n If u &lt; \\alpha(\\theta_{n-1}, \\theta'), then set \\theta_n = \\theta'.\n Otherwise reject the proposal \\theta' and set \\theta_n = \\theta_{n-1}.\nend for\nDiscard first burnin samples and return the remaining samples.\n\n\n\n特に，提案分布が q(\\theta_{n-1}, \\theta') = q(\\theta', \\theta_{n-1}) と対称的である場合は acceptance ratio が\n\n\\alpha(\\theta_{n-1}, \\theta') =\n\\min\\left\\{ 1, \\frac{\\pi(\\theta')}{\\pi(\\theta_{n-1})} \\right\\}\n\nと簡単になり，解釈もしやすくなる．\nつまり，\\theta_{n-1}\\to\\theta' の状態遷移で目標分布 \\pi(\\cdot) の山を登る方向の移動\n\n\\pi(\\theta_{n-1}) \\leqslant \\pi(\\theta') \\iff\n\\frac{\\pi(\\theta')}{\\pi(\\theta_{n-1})} \\geqslant 1\n\nは確率 1 で許可されるが，逆に山を降る方向の移動\n\n\\pi(\\theta_{n-1}) &gt; \\pi(\\theta') \\iff\n\\frac{\\pi(\\theta')}{\\pi(\\theta_{n-1})} &lt; 1\n\nについては，確率 \\alpha(\\theta_{n-1}, \\theta') = \\pi(\\theta') / \\pi(\\theta_{n-1}) で移動が許可される．\n\n\n\nSource: Chib and Greenberg (1995)\n\n\nChib and Greenberg (1995) の図を借りると，\\pi(\\cdot) という山で現在地 x の標高よりも高い地点 y_1 に登る提案は 100% 受け入れられ，標高の低い地点 y_2 に移動する提案は \\alpha(x, y_2) で確率的に受け入れられるということだ．"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html#footnotes",
    "href": "posts/2024/MCMC/metropolis-hastings.html#footnotes",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n一般には採択比率 (acceptance ratio) や採択確率 (acceptance probability) などと呼ばれる．↩︎\n式 2 の不等号の向きがどちらの場合であっても対応できるように \\(\\min\\{\\}\\) を使用．流出する人の数（分母）が流入する人の数（分子）よりも大きい場合のみ交通規制をかけるということ．↩︎\n\\(x=0\\) のとき \\(1\\) をとり，それ以外の \\(x\\) で \\(0\\) をとる関数．↩︎"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html#python-による実装",
    "href": "posts/2024/MCMC/metropolis-hastings.html#python-による実装",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "Python による実装",
    "text": "Python による実装\n上記のMHアルゴリズムを metropolis_hastings() として実装する． 提案分布には平均 \\(\\theta_{t-1}\\)，標準偏差 proposal_std を持つ対称的な正規分布を使用する． したがって，acceptance ratio は目標分布の比に一致する．\nここでは，標準正規分布を目標分布とし，確率密度\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2}\\right)\n\\]\nからMH法によってサンプリングを行う関数を実装する．\n\n実装\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef standard_normal(x):\n    \"\"\"目標分布 f(x) に比例する関数。ここでは標準正規分布を使用。\"\"\"\n    return np.exp(-0.5 * x**2)  # 正規化定数は除く\n\ndef metropolis_hastings(N, x_0, proposal_std):\n    \"\"\"\n    Metropolis-Hastings アルゴリズムによるサンプリング\n    \n    N:            サンプル数\n    x_0:          初期値\n    proposal_std: 提案分布の標準偏差\n    \"\"\"\n\n    samples =[]\n    x = x_0\n\n    for _ in range(N):\n        x_new = np.random.normal(loc=x, scale=proposal_std)\n\n        acceptance_ratio = standard_normal(x_new) / standard_normal(x)\n\n        if np.random.rand() &lt; acceptance_ratio:\n            x = x_new\n\n        samples.append(x)\n\n    return samples\n\n\n\nサンプリング\nmetropolis_hastings() を使って標準正規分布から N=10000 個サンプリングを行い，そのトレースプロットを描いてみる． 初期値は x_0=0 に設定する．\n\n# サンプリング\nsamples1 = metropolis_hastings(N=10000, x_0=0, proposal_std=1.0)\n\n# トレースプロット\nplt.figure(figsize=(8, 4))\nplt.plot(samples1, lw=0.8)\nplt.title('Trace Plot of Samples')\nplt.xlabel('Iteration')\nplt.ylabel('Sample Value')\nplt.show()\n\n\n\n\n\n\n\n\nチェーンの最初の部分は初期値依存性があるので，サンプルの最初の 2000 個を burnin として捨て，残りの 8000 個のヒストグラムと目標分布を重ねて描いてみる．\n\n# サンプルと目標分布のプロット\nplt.figure(figsize=(8, 4))\nplt.hist(samples1[2000:], bins=50, density=True, alpha=0.8, color='#78C2AD', label='Sampled distribution')\nx = np.linspace(-4, 4, 1000)\nplt.plot(x, 1/np.sqrt(2*np.pi) * np.exp(-x**2 / 2), '#FF7A72', lw=2, label='Target distribution N(0,1)')\nplt.title('Metropolis-Hastings Sampling')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nおおよそ目標分布（赤線）を数値的に近似できている様子が見て取れる． 次に，初期値を x_0=3 に変え， N=100000 個サンプリングを行ってみる． サンプルサイズが増えるので，ヒストグラムはより赤線に近い形になるはずである．\n\n# 初期値とサンプルサイズを変えてみる\nsamples2 = metropolis_hastings(N=100000, x_0=3, proposal_std=1.0)\n\n# トレースプロット\nplt.figure(figsize=(10, 4))\nplt.plot(samples2, lw=0.5)\nplt.title('Trace Plot of Samples')\nplt.xlabel('Iteration')\nplt.ylabel('Sample Value')\nplt.show()\n\n\n\n\n\n\n\n\n\n# サンプルと目標分布のプロット\nplt.figure(figsize=(8, 4))\nplt.hist(samples2, bins=50, density=True, alpha=0.8, color='#78C2AD', label='Sampled distribution')\nx = np.linspace(-4, 4, 1000)\nplt.plot(x, 1/np.sqrt(2*np.pi) * np.exp(-x**2 / 2), '#FF7A72', lw=2, label='Target distribution N(0,1)')\nplt.title('Metropolis-Hastings Sampling')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nおまけ：R のコード\n上記の一連の流れを以下の R コードで行うこともできる．\n```{r}\n# 目標分布（標準正規分布）\nstandard_norm &lt;- function(x) {\n    return(exp(-0.5 * x^2))\n}\n\n# MH アルゴリズム\nmetropolis_hastings &lt;- function(x_0, N, proposal_std) {\n    x &lt;- x_0\n    samples &lt;- numeric(N)\n\n    for (n in 1:N) {\n        x_new &lt;- rnorm(1, mean = x, sd = proposal_std)\n\n        acceptance_ratio &lt;- standard_norm(x_new) / standard_norm(x)\n\n        if (runif(1) &lt; acceptance_ratio) {\n            x &lt;- x_new\n        }\n\n        samples[n] &lt;- x\n    }\n    return(samples)\n}\n\n# MH法によるサンプリング\nsamples &lt;- metropolis_hastings(0, 10000, 1.0)\n\n# トレースプロット\nplot(samples, type=\"l\", col=\"blue\", \n    main=\"Trace Plot of MH Sampling\", \n    xlab=\"Iteration\", ylab=\"Sample Value\")\n\n# サンプルのヒストグラムとターゲット分布のプロット\nhist(samples, breaks = 50, probability = TRUE, col = \"lightblue\", \n     main = \"Metropolis-Hastings Sampling\", xlab = \"x\")\n\n# 標準正規分布を重ねてプロット\ncurve(dnorm(x, mean = 0, sd = 1), col = \"red\", lwd = 2, add = TRUE)\n```"
  },
  {
    "objectID": "posts/2024/MCMC/metropolis-hastings.html#metropolis-hastings-アルゴリズム",
    "href": "posts/2024/MCMC/metropolis-hastings.html#metropolis-hastings-アルゴリズム",
    "title": "Metropolis-Hastings アルゴリズム",
    "section": "Metropolis-Hastings アルゴリズム",
    "text": "Metropolis-Hastings アルゴリズム\nMetropolis-Hastings (MH) 法は，目標分布 (target distribution) \\(\\pi(\\cdot)\\) を定常分布にもつマルコフ連鎖を生成するアルゴリズムの一つである．\n前述のベイズ統計学の例で言うと，事後分布 \\(p(\\theta|D)\\) が目標分布 \\(\\pi(\\theta)\\) ということになる． 本稿では引き続きこの例を使用し，パラメータ \\(\\theta \\in \\Theta \\subset \\R^d\\) の従う分布 \\(\\pi(\\theta)\\) を目標分布だと考えて議論を進める．\n\n提案分布の導入\nマルコフ連鎖は，状態空間 (state space) と状態間の遷移確率で規定される． 現時点でわかっていることは，パラメータ \\(\\theta\\) が状態空間 \\(\\Theta\\) の一つの状態を表すということだけで，どのような遷移確率で状態遷移するかは未知である．\nそこで，状態 \\(\\theta\\) の下での提案分布 \\(q(\\theta, \\theta')\\) を適当に導入する． ただし，\\(\\int_\\Theta q(\\theta, \\theta') d\\theta' = 1\\)である． 提案分布はマルコフ連鎖 \\((\\theta_t)\\) が状態 \\(\\theta\\) にあるとき，来期の状態 \\(\\theta'\\) が条件付き確率 \\(q(\\theta, \\theta')\\) で決まることを意味する．\nもし提案分布 \\(q(\\theta, \\theta')\\) が詳細釣り合い条件\n\\[\n\\pi(\\theta)q(\\theta, \\theta') = \\pi(\\theta')q(\\theta', \\theta) \\quad \\forall \\theta, \\theta' \\in \\Theta\n\\tag{1}\\]\nを満たすなら，目標分布 \\(\\pi(\\cdot)\\) を定常分布にもつマルコフ連鎖の遷移確率を得たことになるので，\\(q(\\theta, \\theta')\\) を用いてサンプリングすれば良い． 実際，式 1 の両辺を \\(\\theta'\\) について積分すれば，\\(\\pi(\\cdot)\\) が定常分布であることがわかる：\n\\[\n\\pi(\\theta) = \\int_\\Theta \\pi(\\theta')q(\\theta', \\theta) d\\theta'.\n\\]\nしかし，\\(q(\\theta, \\theta')\\) は適当に設定した分布なので 式 1 は一般には成り立たない． ここで，一般性を失わずに\n\\[\n\\pi(\\theta)q(\\theta, \\theta') &gt; \\pi(\\theta')q(\\theta', \\theta)\n\\tag{2}\\]\nと仮定する． 目標分布 \\(\\pi(\\theta)\\) を状態 \\(\\theta\\) にある人の割合と思えば，式 2 は状態 \\(\\theta\\) から \\(\\theta'\\) に移動する人の割合が，逆に \\(\\theta'\\) から \\(\\theta\\) に移動する人の割合よりも大きいということを表している．\n\n\n状態遷移の制限\n詳細釣り合い条件（式 1）は，両者の割合が同じであってほしいという要請なので，人の移動に交通規制をかけて状態間の移動人数が釣り合うようにしよう． 具体的には，状態 \\(\\theta\\) から \\(\\theta'\\) への移動を制限する確率 \\(\\alpha(\\theta, \\theta') &lt; 1\\) を導入し，\\(\\theta\\) から \\(\\theta'\\) へ移動する人の数を減らせば良い． この任意の2点間の移動を制限する確率 \\(\\alpha(\\cdot, \\cdot) \\in [0,1]\\) をここでは交通規制率と呼ぶことにする1．\n\n\n\n\n\n\nこの時点で考えている問題が，どのような提案分布を設定すべきかという問題から交通規制率を求める問題に変化したことに注意．\n\n\n\n交通規制率を導入すれば，状態 \\(\\theta\\) と \\(\\theta' \\neq \\theta\\) の間の移動は\n\\[\n\\begin{cases}\np_\\text{MH}(\\theta, \\theta') \\equiv q(\\theta, \\theta')\\alpha(\\theta, \\theta') \\\\\np_\\text{MH}(\\theta', \\theta) = q(\\theta', \\theta)\\alpha(\\theta', \\theta)\n\\end{cases}\n\\qquad (\\theta \\neq \\theta')\n\\tag{3}\\]\nに従って行われることになる． 式 2 は \\(\\theta'\\) から \\(\\theta\\) への移動数が不十分だと主張しているので，この方向の移動については規制をかけず \\(\\alpha(\\theta', \\theta) = 1\\) と設定する．\n以上のように \\(\\theta\\) から \\(\\theta'\\) への移動には規制をかけ，\\(\\theta'\\) から \\(\\theta\\) の移動を全て許可すれば，詳細釣り合い条件\n\\[\n\\pi(\\theta)p_\\text{MH}(\\theta, \\theta') = \\pi(\\theta')p_\\text{MH}(\\theta', \\theta)\n\\tag{4}\\]\nが成り立つので，式 3 を使って書き下すと次式を得る：\n\\[\n\\begin{aligned}\n\\pi(\\theta)q(\\theta, \\theta')\\alpha(\\theta, \\theta') &= \\pi(\\theta')q(\\theta', \\theta)\\alpha(\\theta', \\theta) \\\\\n&= \\pi(\\theta')q(\\theta', \\theta).\n\\end{aligned}\n\\]\nこれを \\(\\alpha(\\theta, \\theta')\\) について解けば，\n\\[\n\\alpha(\\theta, \\theta') =\n\\frac{\\pi(\\theta')q(\\theta', \\theta)}{\\pi(\\theta)q(\\theta, \\theta')}\n\\]\nと交通規制率を求めることができる． この \\(\\alpha(\\theta, \\theta')\\) は 式 2 の大小関係の下で導出されたが，不等号が逆向きの場合も同様にして求めることができる．\n一度ここまでの議論をまとめよう．\n\n\n\n\n\n\n\n目標分布 \\(\\pi(\\theta)\\) を定常分布にもつマルコフ連鎖 \\((\\theta_t)\\) の遷移確率が未知なので，代わりに提案分布 \\(q(\\theta, \\theta')\\) を導入した．\n提案分布が詳細釣り合い条件（式 1）を直接満たすとは限らないので，所与の提案分布に対して詳細釣り合い条件が成り立つように交通規制率を次式で定めた2．\n\n\\[\n\\alpha(\\theta, \\theta') =\n\\min\\left\\{ 1, \\frac{\\pi(\\theta')q(\\theta', \\theta)}{\\pi(\\theta)q(\\theta, \\theta')} \\right\\}\n\\qquad (\\theta \\neq \\theta')\n\\tag{5}\\]\n\n\n\n\n\n遷移確率の定式化\nこれまでの議論では，状態遷移 \\(\\theta\\to\\theta'\\) について \\(\\theta' \\neq \\theta\\) であることを暗に仮定していた．MH 法の遷移確率を定式化するには，状態が \\(\\theta\\) にとどまるケース \\(\\theta\\to\\theta\\) も考える必要がある．\n状態が \\(\\theta\\) にとどまる確率は次式で与えられる．\n\\[\n\\begin{aligned}\nr(\\theta)\n&= 1 - \\int_\\Theta p_\\text{MH}(\\theta, \\theta') d\\theta'\\\\\n&= 1 - \\int_\\Theta q(\\theta, \\theta')\\alpha(\\theta, \\theta') d\\theta'\n\\end{aligned}\n\\tag{6}\\]\n式 6 を用いると MH 法の遷移確率 \\(P_\\text{MH}(\\theta, \\theta')\\) は，\n\\[\n\\begin{aligned}\nP_\\text{MH}(\\theta, \\theta')\n&= p_\\text{MH}(\\theta, \\theta') + \\delta(\\theta' -\\theta)r(\\theta) \\\\\n&= q(\\theta, \\theta')\\alpha(\\theta, \\theta') + \\delta(\\theta' -\\theta)r(\\theta)\n\\end{aligned}\n\\tag{7}\\]\nである． ただし，\\(\\delta(x)\\) はディラックのデルタ関数である3．\n\n\n\n\n\n\n命題\n\n\n\n式 7 で与えられるMH 法の遷移確率 \\(P_\\text{MH}(\\theta, \\theta')\\) の下で，目標分布 \\(\\pi(\\cdot)\\) は定常分布である． すなわち，\n\\[\n\\int_\\Theta \\pi(\\theta)P_\\text{MH}(\\theta, \\theta') d\\theta = \\pi(\\theta') \\qquad \\forall\\theta,\\theta'\\in\\Theta.\n\\]\n\n\n\n\n\n\n\n\n証明\n\n\n\n\n\n\\(\\theta,\\theta'\\in\\Theta\\) を任意にとる． 式 4 を用いると次式が成り立つ．\n\\[\n\\begin{aligned}\n\\int_\\Theta \\pi(\\theta)P_\\text{MH}(\\theta, \\theta') d\\theta\n&= \\int_\\Theta \\pi(\\theta)\\left[ p_\\text{MH}(\\theta, \\theta') + \\delta(\\theta' -\\theta)r(\\theta) \\right] d\\theta \\\\\n&= \\int_\\Theta \\textcolor{salmon}{\\pi(\\theta)p_\\text{MH}(\\theta, \\theta')}d\\theta + \\int_\\Theta \\pi(\\theta)\\delta(\\theta' -\\theta)r(\\theta)d\\theta \\\\\n&= \\int_\\Theta \\textcolor{salmon}{\\pi(\\theta')p_\\text{MH}(\\theta', \\theta)}d\\theta + \\pi(\\theta')r(\\theta') \\\\\n&= \\pi(\\theta')\\int_\\Theta p_\\text{MH}(\\theta', \\theta)d\\theta + \\pi(\\theta')\\left[1 - \\int_\\Theta p_\\text{MH}(\\theta', \\theta) d\\theta\\right] \\\\\n&= \\pi(\\theta').\n\\end{aligned}\n\\]\n\n\n\n\n\nMH アルゴリズム\nMH 法をアルゴリズムとして書き下すと，次のようになる．\n\n\n\n\n\n\nPseudocode for Metropolis Hastings method\n\n\n\nInput: The number of samples \\(N\\) and starting point \\(\\theta_0\\).\n\nfor n = 1,…, N do\n Propose \\(\\theta' \\sim q(\\theta_{n-1}, \\theta')\\).\n Compute the acceptance ratio given by\n\n\\[\n\\alpha(\\theta_{n-1}, \\theta') =\n\\min\\left\\{ 1, \\frac{\\pi(\\theta')q(\\theta', \\theta_{n-1})}{\\pi(\\theta_{n-1})q(\\theta_{n-1}, \\theta')} \\right\\}.\n\\]\n\n Draw \\(u \\sim \\text{Uniform}[0, 1)\\).\n If \\(u &lt; \\alpha(\\theta_{n-1}, \\theta')\\), then set \\(\\theta_n = \\theta'\\).\n Otherwise reject the proposal \\(\\theta'\\) and set \\(\\theta_n = \\theta_{n-1}\\).\nend for\nDiscard first burnin samples and return the remaining samples.\n\n\n\n特に，提案分布が \\(q(\\theta_{n-1}, \\theta') = q(\\theta', \\theta_{n-1})\\) と対称的である場合は acceptance ratio が\n\\[\n\\alpha(\\theta_{n-1}, \\theta') =\n\\min\\left\\{ 1, \\frac{\\pi(\\theta')}{\\pi(\\theta_{n-1})} \\right\\}\n\\]\nと簡単になり，解釈もしやすくなる．\nつまり，\\(\\theta_{n-1}\\to\\theta'\\) の状態遷移で目標分布 \\(\\pi(\\cdot)\\) の山を登る方向の移動\n\\[\n\\pi(\\theta_{n-1}) \\leqslant \\pi(\\theta') \\iff\n\\frac{\\pi(\\theta')}{\\pi(\\theta_{n-1})} \\geqslant 1\n\\]\nは確率 \\(1\\) で許可されるが，逆に山を降る方向の移動\n\\[\n\\pi(\\theta_{n-1}) &gt; \\pi(\\theta') \\iff\n\\frac{\\pi(\\theta')}{\\pi(\\theta_{n-1})} &lt; 1\n\\]\nについては，確率 \\(\\alpha(\\theta_{n-1}, \\theta') = \\pi(\\theta') / \\pi(\\theta_{n-1})\\) で移動が許可される．\n\n\n\nSource: Chib and Greenberg (1995)\n\n\nChib and Greenberg (1995) の図を借りると，\\(\\pi(\\cdot)\\) という山で現在地 \\(x\\) の標高よりも高い地点 \\(y_1\\) に登る提案は 100% 受け入れられ，標高の低い地点 \\(y_2\\) に移動する提案は \\(\\alpha(x, y_2)\\) で確率的に受け入れられるということだ．"
  }
]